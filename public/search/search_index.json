{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Pangenome Graphs","text":""},{"location":"#brief-overview-of-pangenome-graphs","title":"Brief Overview of Pangenome Graphs","text":"<p>A pangenome graph is a graphical representation of the collective genomic information of a set of related organisms. Unlike a traditional linear genome assembly, which represents a single consensus genome sequence, a pangenome graph captures the genetic variation and structural diversity within a population. Pangenome graphs are constructed by integrating multiple genome sequences into a single graph structure that represents the entire set of genetic elements present in the population. This graph structure allows for the identification and visualization of genomic variations, such as single nucleotide polymorphisms (SNPs), insertions, deletions, and structural variations, as well as the relationships between different genomic regions. Pangenome graphs have become an important tool in genomics research, especially in the study of bacterial and viral populations, where genetic diversity is often high.</p>"},{"location":"Graph_based_variant_calling_for_NGS/","title":"NGS data analysis used graph as reference on Nesi","text":"<p> In this workshop, we employes the VG toolkit for NGS data analysis based on pangenome graph reference  </p>"},{"location":"Graph_based_variant_calling_for_NGS/#vg-mapping-preliminaries","title":"vg mapping preliminaries","text":"<p>Although vg contains a number of tools for working with pangenome graphs, it is best-known for read mapping. This is ultimately what many of its users are interested in vg for. In fact, vg contains three mature short read mapping tools:</p> <ul> <li>vg map: the original, highly accurate mapping algorithm</li> <li>vg giraffe: the much faster and still accurate haplotype-based mapping algorithm</li> <li>vg mpmap: the splice-aware RNA-seq mapping algorithm</li> </ul> <p>more details of vg can be found https://github.com/vgteam/vg</p> <p>we use vg map in this workshop </p>"},{"location":"Graph_based_variant_calling_for_NGS/#learning-objectives","title":"Learning objectives","text":"<ul> <li>Map NGS data to graph using vg map</li> <li>Variant calling for NGS data against genome graph </li> </ul>"},{"location":"Graph_based_variant_calling_for_NGS/#use-wgsim-to-simulate-2x150-bp-ngs-data-error-rate-0005-we-choose-five-genomes-for-simulation","title":"use wgsim to simulate 2X150 bp NGS data, error rate 0.005. We choose five genomes for simulation,","text":"<p><pre><code>mkdir graph_NGS\ncd graph_NGS\nmkdir simu_NGS_data\n</code></pre> The script for simulation NGS data <pre><code>#!/bin.bash\n#SBATCH --account       ga03793\n#SBATCH --job-name      5NGS_simulate\n#SBATCH --cpus-per-task 8\n#SBATCH --mem           4G\n#SBATCH --time          1:00:00\nmodule purge\nmodule load SAMtools/1.16.1-GCC-11.3.0\n\ninput_folder=/home/zyang/pg_workshop/dataset_for_pg_workshop/12_genomes_for_NGS_simulation\noutput_folder=/home/zyang/pg_workshop/graph_NGS/simu_NGS_data\n\nfor f in NC_017518_6k.fa ST154_6k.fa ST154Sim_6k.fa ST41Sim_6k.fa ST42Sim_6k.fa\n\ndo\nx=$(basename $f .fa)\necho ${x}\nwgsim $input_folder/${x}.fa -N 1000000 -1 150 -2 150  -e 0.005 -r 0 -R 0 -X 0 $output_folder/${x}.wgsim_er0.005.R1.fq  $output_folder/${x}.wgsim_er0.005.R2.fq\ngzip $output_folder/${x}.wgsim_er0.005.R1.fq\ngzip $output_folder/${x}.wgsim_er0.005.R2.fq\n\ndone\n</code></pre></p>"},{"location":"Graph_based_variant_calling_for_NGS/#build-index-for-graph","title":"build index for graph","text":"<pre><code>mkdir refs\n\n# copy graph to the refs work direvtory \ncp /home/zyang/pg_workshop/vg_deconstruct/4Sim_1K96.gfa /home/zyang/pg_workshop/graph_NGS/refs\n\n#make tem_dir\nmkdir /home/zyang/pg_workshop/graph_NGS/refs/temp_dir\n</code></pre> <pre><code>#!/bin.bash\n#SBATCH --account       ga03793\n#SBATCH --job-name      build_index_for_4SimGraph\n#SBATCH --cpus-per-task 8\n#SBATCH --mem           4G\n#SBATCH --time          1:00:00\nmodule purge\nmodule load vg/1.46.0\n\ncd /home/zyang/pg_workshop/graph_NGS/refs\ndata=/home/zyang/pg_workshop/graph_NGS/refs/*.gfa\ntem_dir=/home/zyang/pg_workshop/graph_NGS/refs/temp_dir\n\nfor f in $data\ndo\nx=$(basename $f .gfa)\n#convert the graph into 256 bp chunks, saving as vg format\nvg mod -X 256 ${x}.gfa &gt;${x}_256.vg\n\n#build index of xg and gcsa index\nvg index -b $tem_dir -t 48 -x ${x}_256.xg -g ${x}_256.gcsa -k 16 ${x}_256.vg\n\n#small graph is ok without prunning, complex graph will need to prune first before generating index\n### pruning: use -M if pruning fails\n#vg prune -u -m node-mapping.tmp -t 48 -k 24 ${x}_256.vg &gt; ${x}_256_chopped.vg\n#vg index ${x}_256_chopped.vg -x ${x}_256_chopped.xg\n### gcsa index\n#vg index -b $tem_dir -t 48  -g ${x}_256_chopped.gcsa  ${x}_256_chopped.vg\ndone\n</code></pre>"},{"location":"Graph_based_variant_calling_for_NGS/#vg-map-ngs-to-graph","title":"vg map NGS to graph","text":"<pre><code>mkdir /home/zyang/pg_workshop/graph_NGS/graph_based_mapping\n```bash\n\n```bash\n#!/bin.bash\n#SBATCH --account       ga03793\n#SBATCH --job-name      vgmap_5e_4Sim\n#SBATCH --cpus-per-task 8\n#SBATCH --mem           4G\n#SBATCH --time          24:00:00\nmodule purge\nmodule load vg/1.46.0\n\ndata=/home/zyang/pg_workshop/graph_NGS/simu_NGS_data/*R1.fq.gz\ninput_folder=/home/zyang/pg_workshop/graph_NGS/simu_NGS_data\noutput=/home/zyang/pg_workshop/graph_NGS/graph_based_mapping\n\nindex=/home/zyang/pg_workshop/graph_NGS/refs/4Sim_1K96_256.gcsa\nbasename=/home/zyang/pg_workshop/graph_NGS/refs/4Sim_1K96_256\n\nfor f in $data\ndo\nx=$(basename $f R1.fq.gz)\necho ${x}\nread1=${x}R1.fq.gz\nread2=$(echo $read1|sed 's/R1.fq.gz/R2.fq.gz/')\necho $read2\n#map paired reads using vg map\nvg map -t 20  -d $basename -g $index  -f $input_folder/$read1 -f $input_folder/$read2 -N $x  &gt; $output/${x}vgmap_4Sim.gam\n#vg stats to check the mapping statistics\nvg stats -a  $output/${x}vgmap_4Sim.gam  &gt;$output/${x}vgmap_4Sim_stats\n\ndone\n</code></pre>"},{"location":"Graph_based_variant_calling_for_NGS/#genotying-known-variants","title":"genotying known variants","text":"<pre><code>mkdir /home/zyang/pg_workshop/graph_NGS/vgmap_12e_sim4_allR10S3_typing\n</code></pre> <p>generate snarls of graph <pre><code>#!/bin.bash\n#SBATCH --account       ga03793\n#SBATCH --job-name      vgmap_generate_snarls\n#SBATCH --cpus-per-task 8\n#SBATCH --mem           4G\n#SBATCH --time          1:00:00\nmodule purge\nmodule load vg/1.46.0\n\ninput_folder=/home/zyang/pg_workshop/graph_NGS/refs\noutput_folder=/home/zyang/pg_workshop/graph_NGS/refs\n\nvg snarls $input_folder/4Sim_1K96_256.xg &gt; $output_folder/4Sim_1K96_256.xg.snarls\n</code></pre></p> <p>genotyping  <pre><code>#!/bin.bash\n#SBATCH --account       ga03793\n#SBATCH --job-name      5e_vgmap_genotying\n#SBATCH --cpus-per-task 8\n#SBATCH --mem           4G\n#SBATCH --time          24:00:00\nmodule purge\nmodule load vg/1.46.0\n\ndata_gam=/home/zyang/pg_workshop/graph_NGS/graph_based_mapping/*.wgsim_er0.005.vgmap_4Sim.gam\ninput=/home/zyang/pg_workshop/graph_NGS/graph_based_mapping\noutput=/home/zyang/pg_workshop/graph_NGS/vgmap_12e_sim4_allR10S3_typing\ngraph_xg=/home/zyang/pg_workshop/graph_NGS/refs/4Sim_1K96_256.xg\nsnarls_file=/home/zyang/pg_workshop/graph_NGS/refs/4Sim_1K96_256.xg.snarls\n\n#compute snarls\n#vg snarls $graph_xg &gt;$snarls_file\nfor f in $data_gam\ndo\nx=$(basename $f .wgsim_er0.005.vgmap_4Sim.gam)\necho ${x}\n#Calculate the surpport reads ingoring mapping and base quality &lt;5\n#vg pack -t 48 -x $graph_xg -g $input/${x}.wgsim_er0.005.vgmap_4Sim.gam -Q 5 -o $output/${x}vgmap_Sim4_256_aln.pack\n#Calculate the surpport reads\nvg pack -t 12 -x $graph_xg -g $input/${x}.wgsim_er0.005.vgmap_4Sim.gam -o $output/${x}vgmap_sim4_256_aln.pack\n\n#call variant using the same coordinates and including reference calls (for following compare)\nvg call -t 12 -m 3,10 $graph_xg -k $output/${x}vgmap_sim4_256_aln.pack -r $snarls_file -a  &gt;$output/${x}vgmap_sim4_256_aln.pack_allR10S3.vcf\n\ndone\n</code></pre></p>"},{"location":"Graph_based_variant_calling_for_NGS/#noverl-variant-calling-using-graph-reference","title":"noverl variant calling using graph reference","text":"<pre><code>mkdir /home/zyang/pg_workshop/graph_NGS/vgmap_5e_sim4_allR10S3_novelcalling </code></pre> <pre><code>#!/bin.bash\n#SBATCH --account       ga03793\n#SBATCH --job-name      5e_vgmap_novelvariant_calling\n#SBATCH --cpus-per-task 8\n#SBATCH --mem           4G\n#SBATCH --time          24:00:00\nmodule purge\nmodule load vg/1.46.0\n\ndata_gam=/home/zyang/pg_workshop/graph_NGS/graph_based_mapping/*.wgsim_er0.005.vgmap_4Sim.gam\ninput=/home/zyang/pg_workshop/graph_NGS/graph_based_mapping\noutput=/home/zyang/pg_workshop/graph_NGS/vgmap_5e_sim4_allR10S3_novelcalling\ngraph_vg=/home/zyang/pg_workshop/graph_NGS/refs/4Sim_1K96_256.vg\ngraph_xg=/home/zyang/pg_workshop/graph_NGS/refs/4Sim_1K96_256.xg\n\n#compute snarls\n#vg snarls $graph_xg &gt;$output/${graph_xg}.snarls\nfor f in $data_gam\ndo\nx=$(basename $f .wgsim_er0.005.vgmap_4Sim.gam)\necho ${x}\n#in order to also consider novel variants from the reads, use the augmented graph and gam (as created in the \"Augmentation\" example using vg augment -A)\n#Augment augment the graph with all variation from the GAM, saving to aug.vg\n### augment the graph with all variation from the GAM except\n### that implied by soft clips, saving to aug.vg\n###\u00a0*aug-gam contains the same reads as aln.gam but mapped to aug.vg\nvg augment -t 12 $graph_vg $input/${x}.wgsim_er0.005.vgmap_4Sim.gam -A $output/${x}nofilt_aug.gam &gt;$output/${x}nofilt_aug.vg\n\n#index the augmented graph\nvg index -t 12 $output/${x}nofilt_aug.vg -x $output/${x}nofilt_aug.xg\n\n## Compute the all read support from the augmented gam\nvg pack -t 12 -x $output/${x}nofilt_aug.xg -g $output/${x}nofilt_aug.gam  -o $output/${x}nofilt_aug_allR.pack\n\n#call variant\nvg call -t 12 -m 3,10 $output/${x}nofilt_aug.xg -k $output/${x}nofilt_aug_allR.pack &gt;$output/${x}nofilt_aug_allR.pack.vcf\n\n#call variant snarl using the same coordinate\n#vg call -t 48 -m 3,10 $output/${x}nofilt_aug.xg -k $output/${x}nofilt_aug_allR.pack -a &gt;$output/${x}nofilt_aug_allR.pack_snarls.vcf\ndone\n</code></pre>"},{"location":"Intro_1/","title":"Pangenome Graphs Workshop","text":"<p> This repository contains material to construct pangenome graphs for a small bacteria dataset detailing every step in the Nesi environment. This study includes an anaysis of Neisseria Bacteria genome sequence data with 4Sim data samples to construct pangenome graphs to identify genetic variation and structural variance. </p>"},{"location":"Intro_1/#brief-overview-of-pangenome-graphs","title":"Brief Overview of Pangenome Graphs","text":"<p> A pangenome graph is a graphical representation of the collective genomic information of a set of related organisms. Unlike a traditional linear genome assembly, which represents a single consensus genome sequence, a pangenome graph captures the genetic variation and structural diversity within a population. Pangenome graphs are constructed by integrating multiple genome sequences into a single graph structure that represents the entire set of genetic elements present in the population. This graph structure allows for the identification and visualization of genomic variations, such as single nucleotide polymorphisms (SNPs), insertions, deletions, and structural variations, as well as the relationships between different genomic regions. Pangenome graphs have become an important tool in genomics research, especially in the study of bacterial and viral populations, where genetic diversity is often high.  </p>"},{"location":"Intro_1/#neisseria-genome-assembly","title":"Neisseria Genome Assembly","text":"<p> Neisseria is a genus of Gram-negative bacteria that are typically found in the mucous membranes and epithelial tissues of humans and animals. There are various species of Neisseria bacteria, some of which are harmless commensals, while others can cause diseases. Two well-known pathogenic species are Neisseria meningitidis, which can cause meningitis and septicemia, and Neisseria gonorrhoeae, which is the causative agent of the sexually transmitted infection gonorrhea. Other species of Neisseria are generally considered harmless and reside as commensals in the oral and/or nasopharynx of humans.  </p>"},{"location":"Intro_1/#pangenome-graph-builder-pggb","title":"PanGenome Graph Builder (PGGB)","text":"<p> To investigate and analyse Neisseria Bacteria the PanGenome Graph Builder has been used. PanGenome Graph Builder (PGGB) is a computational tool used in genomics research to construct pan-genome graphs from large sets of genomic data. A pan-genome is the collection of all the genes and non-coding sequences present in a species or a group of related organisms. PGGB constructs a pan-genome graph, which is a data structure that represents the entire set of genes and genetic variations in a population. This graph can be used to study genetic diversity, gene function, and evolution. PGGB is designed to be scalable and efficient, making it suitable for large-scale genomic analyses. It is an open-source tool that can be used freely by researchers in the field of genomics. </p>"},{"location":"Intro_1/#how-does-the-pggb-graph-build-work","title":"How does the pggb graph build work?","text":"<p>The pggb algorithm facilitates the construction of these graphs by progressively integrating genetic variants into a reference genome. The key features and purpose of the PGGb include: 1.  Progressive Approach: The PGGb algorithm follows a step-by-step approach, iteratively adding genetic variants to the graph one at a time. 2.  Variant Integration: The tool efficiently integrates genetic variants, including single nucleotide variations (SNVs), insertions, deletions, and larger structural variations, into the graph representation. 3.  Optimal Placement: For each variant, the PGGb algorithm determines the most suitable position to incorporate it into the graph. This involves aligning the variant sequence with the existing graph structure while minimizing conflicts with the nodes and edges. 4.  Graph Expansion: Once the optimal placement is determined, the PGGb algorithm expands the graph by adding new nodes and edges to represent the variant sequence. The overall graph structure is modified to connect the variant nodes with the adjacent reference nodes. 5.  Large-Scale Graph Construction: The PGGb algorithm is designed to handle large-scale genomes and can efficiently construct genome graphs containing extensive genetic variations.</p>"},{"location":"Intro_1/#all-to-all-alignment","title":"All-to-all alignment","text":"<p>Generally, refers to the process of aligning all sequences in a given set against each other, rather than aligning them to a single reference sequence. We begin with an alignment, with wfmash. This compares all sequences to each other and finds the best N mappings for each. It produces base-level alignments.</p>"},{"location":"Intro_1/#inducing-the-graph","title":"Inducing the graph","text":"<p>Refers to the process of constructing the genome graph by progressively integrating genetic variants into a reference genome. These base-level alignments are converted into a graph with seqwish. A filter is applied to remove short matches, which anchors the graph on confident longer exact matches.</p>"},{"location":"Intro_1/#normalizing-the-graph","title":"Normalizing the graph","text":"<p>refers to a process that aims to optimize the structure and representation of the genome graph by resolving redundant or overlapping elements. This step is typically performed after the initial construction of the graph. The normalization process in PGGb involves several steps, which may vary depending on the specific implementation or version of the tool. Here are some common steps involved in normalizing the graph: 1.  Removal of Redundant Nodes: During the construction of the genome graph, it is possible that some nodes become redundant due to overlapping or repetitive sequences. Normalization involves identifying and removing these redundant nodes, streamlining the graph structure. 2.  Edge Optimization: In the graph, edges represent connections between nodes. During normalization, the edges are optimized to minimize redundancy and improve the efficiency of the graph. This can include merging or repositioning edges to create a more streamlined and accurate representation of the genome. 3.  Compact Representation: Normalization aims to reduce the overall size of the graph by compacting the representation. This can involve compressing repetitive regions or simplifying complex structures while preserving the essential information and variant representation. 4.  Graph Refinement: The normalization process also involves refining the graph structure by resolving inconsistencies, correcting errors, and improving the overall quality of the graph representation. This may include resolving conflicts between nodes and edges, addressing mismatches, and ensuring the graph accurately reflects the underlying genetic variations</p> <p>To normalize the graph and harmonize the allele representation, we use smoothxg to apply a local MSA across all parts of the graph.</p>"},{"location":"Intro_1/#downstream","title":"Downstream","text":"<p>These graphs offer a wide range of capabilities. Initially, we can generate several diagnostic visualizations derived from the graphs, providing a user-friendly way to comprehend the alignments at a broader level. Additionally, using the PGGb tool, we can generate variant calls by leveraging vg deconstruct. The graphs produced by PGGb serve as reference systems for aligning short reads through vg giraffe or long reads through GraphAligner. Furthermore, odgi allows us to utilize the graphs as reference systems to elucidate homology relationships across entire genomes.</p>"},{"location":"Intro_1/#pangenome-graph-evaluator-pgge","title":"PanGenome Graph Evaluator (PGGE)","text":"<p> The pangenome graph evaluation is a pipeline in the pangenome graphs, which measures the reconstruction accuracy of the graph. It helps find the best pangenome graph using input data and tasks. </p>"},{"location":"Intro_1/#learning-objectives","title":"Learning Objectives","text":"<ol> <li>Creating scripts in specific work directory in the Nesi environment.</li> <li>Downloading and preparing sequencing data (in fasta format). </li> <li>Creating Pangenome graphs using PGGB and PGGE Tools.</li> <li>Identifying genetic variation and structural variance.</li> </ol>"},{"location":"Intro_1/#working-in-the-nesi-environment","title":"Working in the Nesi Environment","text":"<p>NeSI HPC environment is used for the analysis. Please make sure to have a NeSI account and you are able to login.</p>"},{"location":"Intro_1/#setting-up-your-project-directory","title":"Setting up your project directory","text":"<pre><code># Create a new directory in somewhere and change to that directory\nmkdir pg_workshop\ncd pg_workshop\n# Keep a note of the absolute path of your directory\npwd\n/nesi/nobackup/nesi02659/pg_workshop\n</code></pre>"},{"location":"Intro_1/#genome-data","title":"Genome Data","text":""},{"location":"Intro_1/#genome-availability","title":"Genome Availability","text":"<p>The National Library of Medicine is the largest library focused on biomedicine worldwide, serving as the central hub for biomedical informatics and computational biology. It has many genome assembly data and Genome assembly ASM19152v1 will be used for this workshop. </p>"},{"location":"Intro_1/#procedure","title":"Procedure","text":""},{"location":"Intro_1/#1-downloading-and-preparing-assembly-data-file-4simfa","title":"1. Downloading and preparing assembly data file 4Sim.fa","text":"<p>Please follow the proedure described in this page</p>"},{"location":"Intro_1/#2-creating-an-index-for-the-seuqence-file-and-check","title":"2. Creating an index for the seuqence file and check","text":"<pre><code>#Use samtools to create the index file\n#In Nesi environment you will have to load the command first\n$ module load SAMtools\n\n$ samtools faidx ASM19152v1_pgsim.fa $ $ cat ASM19152v1_pgsim.fa.fai NC_017518.1     2248966 64      80      81\nNC_017518.1_SNP_5000    2248966 2277165 2248966 2248967\nNC_017518.1_INDEL_5000  2249048 4526156 2249048 2249049\nNC_017518.1_SNP_4000_INDEL_4000 2242147 6775238 2242147 2242148\nNC_017518.1_SNP_4000_INDEL_4000_INV_4   2242147 9017425 2242147 2242148\nNC_017518.1_SNP_4000_INDEL_4000_CNV_4   2415498 11259612        2415498 2415499\n</code></pre> <p>As per the index this assembly consists of 6 samples described in the below table. </p> Name Length SNPs INDELs INV CNV NC_017518.1 (Reference) 2,248,966 N/A N/A N/A N/A NC_017518.1_SNP_5000 2,248,966 5,000 0 0 0 NC_017518.1_INDEL_5000 2,249,048 0 5,000 0 0 NC_017518.1_SNP_4000_INDEL_4000 2,153,883 4,000 4,000 0 0 NC_017518.1_SNP_4000_INDEL_4000_INV_4 2,242,147 4,000 4,000 4 0 NC_017518.1_SNP_4000_INDEL_4000_CNV_4 2,415,498 4,000 4,000 0 4"},{"location":"Intro_1/#3-executing-pggb-tool-using-singularity-container","title":"3. Executing <code>pggb</code> tool using Singularity container","text":"<p>We can follow the procedure in https://github.com/pangenome/pggb#singularity to setup the Singularity image. This is already done and the image is in <code>/nesi/project/nesi02659/software/pggb/</code> directory for version 0.5.3. </p> <p>Following script (pggb_test.sh) can be used to run <code>pggb</code> on the downloaded sequence. </p> <pre><code>#!/bin.bash\nmodule load Singularity\n#export container to a variable for convenience\nWD=/nesi/nobackup/nesi02659/pg_workshop #Working Directory\ncontainer=/nesi/project/nesi02659/software/pggb/pggb_0.5.3.simg\ndata=${WD}/ASM19152v1_pgsim.fa\n\nsingularity exec ${container} pggb -i $data -s 1000 -p 95 -n 6 -k 79 -t 2 -S -m -o output -V 'NC_017518.1:#' </code></pre> <p>In <code>pggb</code> <code>-i</code> is for specifying the sequence file. <code>-s</code> specifies the segment length for mapping and <code>-p</code> specifies percent identity for mapping/alignment. <code>-n</code> is for number of haplotypes (or number of samples). <code>-k</code> for minimum matching length. <code>-t</code> says number of threads to be used for the execution. <code>-S</code> will generate the stats. <code>-m</code> will generate MultiQC report of graphs' statistics and visualizations. <code>-o</code> specifies the output directory name. <code>-V 'NC_017518.1:#'</code> will create a vcf file and its stats considering NC_017518.1 as the reference sequence. </p> <p>You can run run pggb without parameters to get information on the meaning of each parameter. Noe take a look at the files in the \"output\" folder. We get a graph in GFA (.gfa) and odgi (.og) formats. These can be used downstream in many methods, including those in vg, like vg giraffe. You can visualize the GFA format graph with BandageNG, and use odgi directly on the *.gfa or *.og output. </p>"},{"location":"Intro_1/#executing-pggb-as-a-slurm-job","title":"Executing <code>pggb</code> as a SLURM Job","text":"<p>Executing shell scripts in the Nesi environment might not be the best way to handle larger files which will require large memory, CPU power and time. We can modify the previusely explained script as below (pggb_slurm_1K95.sh) to run as SLURM job. Note the additional parameters specified by <code>#SBATCH</code> which will indicate maximum resource limitations. </p> <pre><code>#!/bin.bash\n#SBATCH --account       ga03793\n#SBATCH --job-name      NC_017518.1_1K95\n#SBATCH --cpus-per-task 8 \n#SBATCH --mem           4G\n#SBATCH --time          1:00:00\nmodule purge\nmodule load Singularity\n\n#export container to a variable for convenience\nWD=/nesi/nobackup/nesi02659/pg_workshop #Working Directory\ncontainer=/nesi/project/nesi02659/software/pggb/pggb_0.5.3.simg\ndata=${WD}/ASM19152v1_pgsim.fa\n\nsingularity exec ${container} pggb -i $data -s 1000 -p 95 -n 6 -k 79 -t 24 -S -m -o output_1K95 -V 'NC_017518.1:#'  </code></pre> <p>The job can be submitted using the <code>sbatch</code> command it will show a job id. In this case 35887085</p> <pre><code>$ sbatch pggb_slurm_1K95.sh\nSubmitted batch job 35887085\n</code></pre> <p>We can monitor the job status using <code>seff</code> and <code>squeue</code> specifying the job id. </p> <pre><code>seff 35887085\nJob ID: 35887085\nCluster: mahuika\nUser/Group: ismnu81p/ismnu81p\nState: RUNNING\nNodes: 1\nCores per node: 8\nCPU Utilized: 00:00:00\nCPU Efficiency: 0.00% of 00:04:16 core-walltime\nJob Wall-clock time: 00:00:32\nMemory Utilized: 0.00 MB (estimated maximum)\nMemory Efficiency: 0.00% of 4.00 GB (4.00 GB/node)\nWARNING: Efficiency statistics may be misleading for RUNNING jobs.\n</code></pre> <pre><code>$ squeue --job 35887085\nJOBID         USER     ACCOUNT   NAME        CPUS MIN_MEM PARTITI START_TIME     TIME_LEFT STATE    NODELIST(REASON)    \n35887085      ismnu81p ga03793   NC_017518.1_   8      4G large   2023-05-21T0       58:35 RUNNING  wbn063 \n</code></pre> <p>SLURM will also create a output log file and we can monitor it realtime using  <code>tail -f</code>. </p> <pre><code>$ tail -f slurm-35887085.out [smoothxg::(1-3)::prep] writing graph output_1K95/ASM19152v1_pgsim.fa.2ab4142.c2fac19.seqwish.gfa.prep.0.gfa\n[smoothxg::(1-3)::main] building xg index\n[smoothxg::(1-3)::smoothable_blocks] computing blocks\n[smoothxg::(1-3)::smoothable_blocks] computing blocks for 54747 handles: 100.00% @ 5.47e+04/s elapsed: 00:00:00:01 remain: 00:00:00:00\n[smoothxg::(1-3)::break_and_split_blocks] cutting blocks that contain sequences longer than max-poa-length (1400) and depth &gt;= 0\n[smoothxg::(1-3)::break_and_split_blocks] splitting 3862 blocks at identity 0.950 (WFA-based clustering) and at estimated-identity 0.950 (mash-based clustering)\n[smoothxg::(1-3)::break_and_split_blocks] cutting and splitting 3862 blocks: 100.00% @ 1.49e+04/s elapsed: 00:00:00:00 remain: 00:00:00:00\n[smoothxg::(1-3)::break_and_split_blocks] cut 0 blocks of which 0 had repeats\n[smoothxg::(1-3)::break_and_split_blocks] split 0 blocks\n[smoothxg::(1-3)::smooth_and_lace] applying local SPOA to 3862 blocks: 78.40% @ 5.77e+01/s elapsed: 00:00:00:52 remain: 00:00:00:14\n</code></pre> <p>When the job is completed the <code>seff</code> command will show a summary report with below details. The job has used 785.61 MB memory and taken 7 minuted and 50 seconds to complete. </p> <pre><code>$ seff 35887085\nJob ID: 35887085\nCluster: mahuika\nUser/Group: ismnu81p/ismnu81p\nState: COMPLETED (exit code 0)\nNodes: 1\nCores per node: 8\nCPU Utilized: 00:41:23\nCPU Efficiency: 66.04% of 01:02:40 core-walltime\nJob Wall-clock time: 00:07:50\nMemory Utilized: 785.61 MB\nMemory Efficiency: 19.18% of 4.00 GB\n</code></pre> <p>Now we can try the same script by changing the <code>pggb</code> parameters <code>-s</code>, <code>-p</code> and <code>-k</code> and compare the results. Please refer script folder for scripts. </p>"},{"location":"Intro_1/#understanding-odgi-visualizations","title":"Understanding odgi visualizations","text":"<p>We obtain a series of diagnostic images that represent the pangenome alignment. These are created with odgi viz (1D matrix) and odgi layout with odgi draw (2D graph drawings). First, the 2D layout gives us a view of the total alignment. For small graphs, we can look at the version that shows where specific paths go (*.draw_multiqc.png): For larger ones, the *.draw.png result is usually more legible.</p>"},{"location":"Intro_1/#the-effect-of-haplotype-count-n","title":"The effect of haplotype count <code>-n</code>","text":"<p>What happens if we set a lower <code>-n</code>? This parameter determines how many mappings we have. Each sequence is aligned against its n-1 best matches. Setting -n 6 causes clustering of sequences into groups that are more similar.</p>"},{"location":"Intro_1/#the-effect-of-the-minimum-match-filter-k","title":"The effect of the minimum match filter <code>-k</code>","text":"<p>Another key parameter is -k, which affects the behavior of seqwish. This filter removes exact matches from alignments that are shorter than -k. Short matches occur in regions of high diversity. In practice, these short matches contribute little to the overall structure of the graph, and we remove them to further simplify the base graph structure.</p>"},{"location":"Intro_1/#decreasing-mapping-segment-length-s-increases-sensitivity","title":"Decreasing mapping segment length <code>-s</code> increases sensitivity","text":"<p>By setting a lower mapping segment length, which affects the behavior of the very first step in the pipeline, wfmash\u2019s mapping step (itself based on a heavily modified version of MashMap). This defaults to -s 5k. We can use -s 1k to guarantee we pick up on smaller homology segments, leading to a more complete alignment.</p>"},{"location":"Intro_1/#multiqc-report","title":"MultiQC Report","text":"<p>The script generated output directory consists of a compehensive and interactive MutltiQC Report which will decribe all. Open the file multiqc_report.html which is in the output folder from your browser.</p> <p>Note: To download the output folder from the Nesi environment you can first zip it using the command <code>zip -r output.zip output</code></p>"},{"location":"Intro_1/#graph-viszualization-details-s-1000-p-95","title":"Graph Viszualization Details (<code>-s 1000</code>, <code>-p 95</code>)","text":""},{"location":"Intro_1/#odgi-compressed-1d-visualization","title":"ODGI Compressed 1D visualization","text":""},{"location":"Intro_1/#odgi-1d-visualization","title":"ODGI 1D visualization","text":""},{"location":"Intro_1/#odgi-1d-visualization-by-path-position","title":"ODGI 1D visualization by path position","text":""},{"location":"Intro_1/#odgi-1d-visualization-by-path-orientation","title":"ODGI 1D visualization by path orientation","text":""},{"location":"Intro_1/#odgi-1d-visualization-by-node-depth","title":"ODGI 1D visualization by node depth","text":""},{"location":"Intro_1/#odgi-1d-visualization-by-uncalled-bases","title":"ODGI 1D visualization by uncalled bases","text":""},{"location":"Intro_1/#odgi-2d-drawing","title":"ODGI 2D drawing","text":""},{"location":"Intro_1/#compare-accuracies-of-mapping-reads-using-linear-methods-and-graph-methods","title":"Compare accuracies of mapping reads using linear methods and graph methods","text":""},{"location":"Intro_2/","title":"Intro 2","text":"<p> This repository includes sample datasets and scripts, which are utilized for the construction of pangenome graphs. It provides a comprehensive walkthrough of each step executed within the Nesi environment. </p>"},{"location":"Intro_2/#pangenome-graphs-workshop","title":"Pangenome Graphs Workshop","text":"<p> Unlock the Power of Pangenome Graphs in Bioinformatics  ![example of pangenome graph in 2D visulization](https://github.com/ZoeYang2020/Pangenome-Graphs-Workshop/blob/main/Figures/DRB1-3123.fa.gz.pggb-E-s5000-l15000-p80-n10-a0-K16-k8-w50000-j5000-e5000-I0-R0-N.smooth.chop.og.lay.draw_mqc.png?raw=true])   Don't let reference bias hinder your genomic analysis! Discover the cutting-edge potential of pangenome graphs in our pangenome workshop.   In the field of bioinformatics, relying on a single reference genome can lead to significant oversights in genome variability and relationships. Luckily, recent advancements in assembly methods have made generating high-quality complete genome assemblies more accessible than ever before. Now is the time to leverage the full potential of pangenome graphs.   Our workshop delves into the construction of dynamic pangenome graphs that incorporate multiple genomes and their alignments. By representing all types of variations within a graph structure, pangenome graphs provide an efficient model for analyzing complex genomic data.  Throughout the workshop, we will guide you through a practical pangenome bioinformatics pipeline, utilizing the PanGenome Graph Builder and the Variation Graph toolkit. You will learn how to construct pangenomes from assembled genomes, align whole genome sequencing data, and call variants against a graph reference.  Gain a deep understanding of pangenome concepts and gain hands-on experience building and analyzing pangenome graphs. Discover how to apply these methods to tackle intricate research questions that involve understanding the intricate relationships between multiple genomes or accounting for variability in new genome analyses. By the end of the course, you will possess a strong grasp of pangenome methods based on whole genome assemblies.  </p>"},{"location":"Intro_2/#acknowledgments","title":"Acknowledgments","text":"<p>Erik Garrison, Andrea Guarracino, Nuzla Ismail, Patrick J. Biggs, Una Ren, Michael A Black, and Joep de Ligt</p>"},{"location":"Intro_2/#brief-overview-of-the-pangenome-graph-workflow","title":"Brief Overview of the pangenome graph workflow","text":"<p> A pangenome is defined as the comprehensive collection of whole-genome sequences from multiple individuals within a clade, a population or a species. This collective genomic dataset can be further divided into two distinct components: the core genome, which includes genes present in all individuals at the time of analysis, and the accessory genome, consisting of genes found only in a subset of individuals (Figure 1A).   Pangenome graphs are pangenomes stored in graph models that can capture the entire genetic variation among genomes in a population or of a set of related organisms (Figure 1B). There are three components of a variation graph: Nodes, edges and paths.   **Nodes** - DNA segments, which can be any length   **Edges**  - describe the possible ways of walking through the nodes - connect pairs of node strands - can represent inversions   **Paths are walk through the nodes of the graph**  - genomes - haplotypes - alleles/variants   This pipeline for pangenome graph comprises three key stages: graph construction using PGGB, graph manipulation via ODGI, and variant calling for Next-Generation Sequencing (NGS) data utilizing the VG toolkit, as shown in Figure 1C.  The PGGB pipeline, which operates without a reference method, builds pangenome graphs using an all-to-all whole genome alignment approach with wfmash. Subsequent graph induction is accomplished through seqwish, followed by progressive normalization implemented with smoothxg and gfaffix.  ODGI is employed for various graph manipulation tasks, including visualization and the extraction of distances between paths within the graph. This feature enables further phylogenetic analysis.  By using the pangenome graph created with PGGB, it is possible to concurrently identify a variety of genetic variations. These include structural sariations (SVs), rearrangements, and smaller variants such as single nucleotide polymorphisms (SNPs) and insertions/deletions, which can be identified through the 'vg deconstruction' process.  Lastly, the VG toolkit is harnessed for NGS data analysis against the graph, which includes tasks like read mapping and variant calling.   </p> <p></p>"},{"location":"Intro_2/#tools-used-in-this-pipeline","title":"Tools used in this pipeline","text":"<p>The tools used for the pangenome graph pipeline</p> <ul> <li> <p>graph construction using the PanGenome Graph Builder (PGGB) (https://github.com/pangenome/pggb)</p> </li> <li> <p>graph manipulation through the Optimized Dynamic Genome/Graph Implementation (ODGI)(https://github.com/pangenome/odgi)</p> </li> <li> <p>variant calling for Next-Generation Sequencing (NGS) data using the VG toolkit(https://github.com/vgteam/vg)</p> </li> <li> <p>https://github.com/marbl/Mash</p> </li> <li>https://github.com/samtools/samtools</li> <li>https://github.com/yjx1217/simuG</li> <li>https://github.com/pangenome/pgge</li> <li>https://github.com/samtools/bcftools</li> </ul>"},{"location":"Intro_2/#datasets-used-in-this-pipeline","title":"Datasets used in this pipeline","text":"<p> For this workshop, we utilized the genomes of the bacterium Neisseria meningitidis as a representative example.  Neisseria (N.) meningitidis, also known as the meningococcus pathogen, is the primary agent responsible for invasive meningococcal diseases such as meningitis and septicemia, causing isolated incidents, outbreaks, and epidemics worldwide. The genome of this bacterium spans approximately 2.1 to 2.4 Mb and possesses a GC content ranging from 51-52%. One striking characteristic of N. meningitidis genomes is their high recombination rate, which largely fuels the extensive genetic diversity within this species. In this workshop, we utilized both real and simulated genomic data of N. meningitidis to assess the pangenome pipeline, covering pangenome graph construction to variant calling.   In Aotearoa New Zealand (NZ), from 1991 to 2007, an extended serogroup B epidemic occurred due to a single strain known as NZMenB (designated B:4:P1.7-2,4), identified by the PorA variant (P1.7-2), which still accounts for around one-third of meningococcal disease cases in NZ. Based on our unpublished WGS data, we have categorized NZMenB into three phylogenetic clades, namely, clade154, clade41 and clade42 based on the multilocus sequence types (MLST) of seven housekeeping genes for sequence type (ST), ST154, ST41 and ST42 respectively.   Mauve alignments demonstrated large inversions among the 3ST genomes.  ![Mauve alignment of the 3STs genomes](https://github.com/ZoeYang2020/Pangenome-Graphs-Workshop/blob/main/Figures/Fig.3ST_mauve%20alignment.png??raw=true]) To evaluate pangenome graph construction, we simulated three genomes from NC_017518 (ST42) by introducing either randomly generated SNPs or mutated according to the SNP differences of ST41 and ST154 relative to ST42. The simulation was followed by introducing 200 indels and two inversions using simuG(https://github.com/yjx1217/simuG). We named the three simulated genomes ST42Sim, ST41Sim, and ST154Sim. The three simulated genomes contained 200 indels and two inversions relative to ST42, with ST42Sim, ST41Sim and ST154Sim containing 5000, 2892 and 4283 SNPs respectively. We grouped the three simulated genomes with ST42, which we refer to as the 4Sim genomes. We used the 4Sim and 3ST genomes as examples for pangenome graph construction in this workshop.      To expand our evaluation of pangenome graph construction to more diverse genomes, 24 N. meningitidis (NM) genomes were downloaded from NCBI.   ### Three datasets used in this pipeline for pangenome graph construction    - the 4Sim genomes  - the 3STs genomes of NZmenB   - 24NM genomes    We used simulated NGS dataset of N. meningitidis for pangenome graph based variant calling  In addition to the comparative genomics analysis of the paths (genomes) based on the genome graphs, these graphs can also serve as a pangenome reference for NGS data analysis. To evaluate the genome graph-based pipeline for NGS data mapping and variant calling using the VG toolkit, we simulated 100x read depth 2x150bp paired NGS data with an error rate of 0.5% using wgsim from samtools. We began with six genomes, which included the 3ST genomes and the three simulated genomes. To generate a set of six genomes, we initially introduced 6000 SNPs for each of the six genomes using SimuG. Consequently, we obtained 12 genomes distributed among six groups, including ST42, ST42Sim, ST41, ST41Sim, ST154, and ST154Sim.  ### 12 simulated NGS data used for pangenome graph based NGS data analysis    - NC_017518  - NC_017518_6k  - ST154  - ST154_6k  - ST154Sim  - ST154Sim_6k  - ST41  - ST41_6k  - ST41Sim  - ST41Sim_6k  - ST42Sim  - ST42Sim_6k  </p>"},{"location":"Intro_2/#learning-objectives","title":"Learning Objectives","text":"<p>Participants will learn about pangenome concepts and gain practical experience building and analyzing pangenome graphs. They will apply these methods to complex research questions that require understanding the relationships between multiple genomes or accounting for variability when analyzing new genomes. By the end of the course, participants will have a strong understanding of pangenome methods based on whole genome assemblies. 1. Develop scripts within a specific work directory in the Nesi environment. 2. Downloading and preparing sequencing data (in fasta format).  3. Construct graphs using the PanGenome Graph Builder (PGGB) (https://github.com/pangenome/pggb) 4. Manipulate graphs using the Optimized Dynamic Genome/Graph Implementation (ODGI)(https://github.com/pangenome/odgi) 5. variant calling for Next-Generation Sequencing (NGS) data using the VG toolkit(https://github.com/vgteam/vg)</p>"},{"location":"mapping_reads/","title":"Mapping Reads using <code>bwa mem</code> (Linear Method)","text":"<p>Note: folder : /nesi/nobackup/nesi02659/pg_workshop/vc_exact_compare/ We can use below script to map the reads to the reference sequnce using linear method <code>bwa mem</code>.  <pre><code>#Load required modules with specific versions\nmodule purge\nmodule load BCFtools/1.9-GCC-7.4.0\nmodule load SAMtools/1.9-GCC-7.4.0\nmodule load BWA/0.7.17-GCC-9.2.0\nmodule load wgsim/20111017-GCC-11.3.0\n\nmkdir vc_exact_compare\ncd vc_exact_compare\n\n#Copy the below files into the folder\n$ ls -1trhs\ntotal 14M\n2.3M GCF_000191525.1_ASM19152v1_genomic.fna\n2.3M Simulation_INDEL_5000.simseq.genome.fa\n2.5M Simulation_SNP_4000_INDEL_4000_CNV_4.simseq.genome.fa\n2.3M Simulation_SNP_4000_INDEL_4000_INV_4.simseq.genome.fa\n2.3M Simulation_SNP_4000_INDEL_4000.simseq.genome.fa\n2.3M Simulation_SNP_5000.simseq.genome.fa\n\n#indexing the reference sample\nbwa index GCF_000191525.1_ASM19152v1_genomic.fna </code></pre> In order to simulate a real sequensing experiment, we'll simulate the short reads too from the simulated full sequence using <code>wgsim</code> and map those reads to the reference sequnce using <code>bwa</code>. Since the length of the each sequnce is around 2.3 million, 0.7 millions of 100pb reads will give 30x read depth. (700000x100/2300000 ~ 30)</p> <pre><code>#creating VCF files for each sample file considering GCF_000191525.1_ASM19152v1_genomic.fna as reference and silulating 30x 100bp reads. \n#export OMP_NUM_THREADS=1\nwgsim -N675000 -1100 -2100 Simulation_SNP_5000.simseq.genome.fa Simulation_SNP_5000.read1.fq Simulation_SNP_5000.read2.fq bwa mem -R \"@RG\\tID:Simulation_SNP_5000\\tSM:Simulation_SNP_5000\\tLB:L1\" GCF_000191525.1_ASM19152v1_genomic.fna Simulation_SNP_5000.read1.fq Simulation_SNP_5000.read2.fq &gt; Simulation_SNP_5000.sam\nsamtools view -bS Simulation_SNP_5000.sam | samtools sort - &gt; Simulation_SNP_5000.bam\nbcftools mpileup -Ou -f GCF_000191525.1_ASM19152v1_genomic.fna Simulation_SNP_5000.bam | bcftools call -vmO z -o Simulation_SNP_5000.bwa.30x.100R.vcf.gz\nbcftools index Simulation_SNP_5000.bwa.30x.100R.vcf.gz wgsim -N675000 -1100 -2100 Simulation_INDEL_5000.simseq.genome.fa Simulation_INDEL_5000.read1.fq Simulation_INDEL_5000.read2.fq bwa mem -R \"@RG\\tID:Simulation_INDEL_5000\\tSM:Simulation_INDEL_5000\\tLB:L1\" GCF_000191525.1_ASM19152v1_genomic.fna Simulation_INDEL_5000.read1.fq Simulation_INDEL_5000.read2.fq &gt; Simulation_INDEL_5000.sam\nsamtools view -bS Simulation_INDEL_5000.sam | samtools sort - &gt; Simulation_INDEL_5000.bam\nbcftools mpileup -Ou -f GCF_000191525.1_ASM19152v1_genomic.fna Simulation_INDEL_5000.bam | bcftools call -vmO z -o Simulation_INDEL_5000.bwa.30x.100R.vcf.gz\nbcftools index Simulation_INDEL_5000.bwa.30x.100R.vcf.gz wgsim -N675000 -1100 -2100 Simulation_SNP_4000_INDEL_4000.simseq.genome.fa Simulation_SNP_4000_INDEL_4000.read1.fq Simulation_SNP_4000_INDEL_4000.read2.fq bwa mem -R \"@RG\\tID:Simulation_SNP_4000_INDEL_4000\\tSM:Simulation_SNP_4000_INDEL_4000\\tLB:L1\" GCF_000191525.1_ASM19152v1_genomic.fna Simulation_SNP_4000_INDEL_4000.read1.fq  Simulation_SNP_4000_INDEL_4000.read2.fq &gt; Simulation_SNP_4000_INDEL_4000.sam\nsamtools view -bS Simulation_SNP_4000_INDEL_4000.sam | samtools sort - &gt; Simulation_SNP_4000_INDEL_4000.bam\nbcftools mpileup -Ou -f GCF_000191525.1_ASM19152v1_genomic.fna Simulation_SNP_4000_INDEL_4000.bam | bcftools call -vmO z -o Simulation_SNP_4000_INDEL_4000.bwa.30x.100R.vcf.gz\nbcftools index Simulation_SNP_4000_INDEL_4000.bwa.30x.100R.vcf.gz\n\nwgsim -N675000 -1100 -2100 Simulation_SNP_4000_INDEL_4000_INV_4.simseq.genome.fa Simulation_SNP_4000_INDEL_4000_INV_4.read1.fq Simulation_SNP_4000_INDEL_4000_INV_4.read2.fq\nbwa mem -R \"@RG\\tID:Simulation_SNP_4000_INDEL_4000_INV_4\\tSM:Simulation_SNP_4000_INDEL_4000_INV_4\\tLB:L1\" GCF_000191525.1_ASM19152v1_genomic.fna Simulation_SNP_4000_INDEL_4000_INV_4.read1.fq Simulation_SNP_4000_INDEL_4000_INV_4.read2.fq &gt; Simulation_SNP_4000_INDEL_4000_INV_4.sam\nsamtools view -bS Simulation_SNP_4000_INDEL_4000_INV_4.sam | samtools sort - &gt; Simulation_SNP_4000_INDEL_4000_INV_4.bam\nbcftools mpileup -Ou -f GCF_000191525.1_ASM19152v1_genomic.fna Simulation_SNP_4000_INDEL_4000_INV_4.bam | bcftools call -vmO z -o Simulation_SNP_4000_INDEL_4000_INV_4.bwa.30x.100R.vcf.gz\nbcftools index Simulation_SNP_4000_INDEL_4000_INV_4.bwa.30x.100R.vcf.gz\n\nwgsim -N675000 -1100 -2100 Simulation_SNP_4000_INDEL_4000_CNV_4.simseq.genome.fa Simulation_SNP_4000_INDEL_4000_CNV_4.read1.fq Simulation_SNP_4000_INDEL_4000_CNV_4.read2.fq\nbwa mem -R \"@RG\\tID:Simulation_SNP_4000_INDEL_4000_CNV_4\\tSM:Simulation_SNP_4000_INDEL_4000_CNV_4\\tLB:L1\" GCF_000191525.1_ASM19152v1_genomic.fna Simulation_SNP_4000_INDEL_4000_CNV_4.read1.fq Simulation_SNP_4000_INDEL_4000_CNV_4.read2.fq &gt; Simulation_SNP_4000_INDEL_4000_CNV_4.sam\nsamtools view -bS Simulation_SNP_4000_INDEL_4000_CNV_4.sam | samtools sort - &gt; Simulation_SNP_4000_INDEL_4000_CNV_4.bam\nbcftools mpileup -Ou -f GCF_000191525.1_ASM19152v1_genomic.fna Simulation_SNP_4000_INDEL_4000_CNV_4.bam | bcftools call -vmO z -o Simulation_SNP_4000_INDEL_4000_CNV_4.bwa.30x.100R.vcf.gz\nbcftools index Simulation_SNP_4000_INDEL_4000_CNV_4.bwa.30x.100R.vcf.gz\n</code></pre> <p>(You can find above script as a SLURM job script here vc_bwa_compare.sh)</p> <p>Now we can find the variant call stats using <code>bcftools stats</code>. </p> <pre><code>$ bcftools stats Simulation_SNP_5000.bwa.30x.100R.vcf.gz | head -30\n# This file was produced by bcftools stats (1.9+htslib-1.9) and can be plotted using plot-vcfstats.\n# The command line was: bcftools stats  Simulation_SNP_5000.bwa.30x.100R.vcf.gz\n#\n# Definition of sets:\n# ID    [2]id   [3]tab-separated file names\nID      0       Simulation_SNP_5000.bwa.30x.100R.vcf.gz\n# SN, Summary numbers:\n#   number of records   .. number of data rows in the VCF\n#   number of no-ALTs   .. reference-only sites, ALT is either \".\" or identical to REF\n#   number of SNPs      .. number of rows with a SNP\n#   number of MNPs      .. number of rows with a MNP, such as CC&gt;TT\n#   number of indels    .. number of rows with an indel\n#   number of others    .. number of rows with other type, for example a symbolic allele or\n#                          a complex substitution, such as ACT&gt;TCGA\n#   number of multiallelic sites     .. number of rows with multiple alternate alleles\n#   number of multiallelic SNP sites .. number of rows with multiple alternate alleles, all SNPs\n# \n#   Note that rows containing multiple types will be counted multiple times, in each\n#   counter. For example, a row with a SNP and an indel increments both the SNP and\n#   the indel counter.\n# \n# SN    [2]id   [3]key  [4]value\nSN      0       number of samples:      1\nSN      0       number of records:      6740\nSN      0       number of no-ALTs:      0\nSN      0       number of SNPs: 6395\nSN      0       number of MNPs: 0\nSN      0       number of indels:       345\nSN      0       number of others:       0\nSN      0       number of multiallelic sites:   1\n</code></pre>"},{"location":"mapping_reads/#mapping-reads-using-vg-giraffe-graph-method","title":"Mapping Reads using <code>vg giraffe</code> (Graph Method)","text":"<p>Here we map reads to a pangenome graph instead of single linear reference sequence. For example we'll consider the first case <code>Simulation_INDEL_5000.simseq.genome.fa</code>. We can build a graph considering the reference sequence <code>GCF_000191525.1_ASM19152v1_genomic.fna</code> and the ground truth VCF file </p> <p><pre><code>#Load  additional model need for vg\nmodule load vg/1.46.0\n\n#Copy the vcf files into the folder\nls -1trhs Simulation_*.vcf\n768K Simulation_SNP_5000.refseq2simseq.SNP.vcf\n768K Simulation_INDEL_5000.refseq2simseq.INDEL.vcf\n768K Simulation_SNP_4000_INDEL_4000.refseq2simseq.SNP.vcf\n768K Simulation_SNP_4000_INDEL_4000.refseq2simseq.INDEL.vcf\n 512 Simulation_SNP_4000_INDEL_4000_INV_4.refseq2simseq.inversion.vcf\n256K Simulation_SNP_4000_INDEL_4000_CNV_4.refseq2simseq.CNV.vcf\n\n#create tabix index\nbgzip Simulation_SNP_5000.refseq2simseq.SNP.vcf\ntabix Simulation_SNP_5000.refseq2simseq.SNP.vcf.gz\n\n#create the graph and index (-p is prefix for filenames)\nvg autoindex --workflow giraffe -r GCF_000191525.1_ASM19152v1_genomic.fna -v Simulation_SNP_5000.refseq2simseq.SNP.vcf.gz -p VG_SNP_5000\n\n#Map reads to the graph\nvg giraffe -Z VG_SNP_5000.giraffe.gbz -f Simulation_INDEL_5000.read1.fq -f Simulation_INDEL_5000.read2.fq -o SAM &gt; Simulation_VG_SNP_5000.sam\n\n#Follow same procedure for VCF file creation\nsamtools view -bS Simulation_VG_SNP_5000.sam | samtools sort - &gt; Simulation_VG_SNP_5000.bam\nbcftools mpileup -Ou -f GCF_000191525.1_ASM19152v1_genomic.fna Simulation_VG_SNP_5000.bam | bcftools call -vmO z -o Simulation_VG_SNP_5000.giraffe.30x.100R.vcf.gz\nbcftools index Simulation_VG_SNP_5000.giraffe.30x.100R.vcf.gz </code></pre> We can follow the same procedure for the rest of the samples and generate VCF files. </p>"},{"location":"pangenome_graph_construction/","title":"pangenome graph construction with PGGB on Nesi","text":"<p> In this workshop, we employes PanGenome Graph Builder (PGGB) to construction the pangenome graphs </p>"},{"location":"pangenome_graph_construction/#how-does-the-pggb-graph-build-work","title":"How does the pggb graph build work?","text":"<p>pggb builds pangenome variation graphs from a set of input sequences.</p> <p>A pangenome variation graph is a kind of generic multiple sequence alignment. It lets us understand any kind of sequence variation between a collection of genomes. It shows us similarity where genomes walk through the same parts of the graph, and differences where they do not.</p> <p>pggb generates this kind of graph using an all-to-all alignment of input sequences (wfmash), graph induction (seqwish), and progressive normalization (smoothxg, gfaffix). After construction, pggb generates diagnostic visualizations of the graph (odgi). A variant call report (in VCF) representing both small and large variants can be generated based on any reference genome included in the graph (vg). pggb writes its output in GFAv1 format, which can be used as input by numerous \"genome graph\" and pangenome tools, such as the vg and odgi toolkits.</p> <p>pggb has been tested at scale in the Human Pangenome Reference Consortium (HPRC) as a method to build a graph from the draft human pangenome. </p> <p>more details can be find (PGGB)</p>"},{"location":"pangenome_graph_construction/#learning-objectives","title":"Learning objectives","text":"<ul> <li>build pangenome graphs using pggb</li> <li>explore pggb\u2019s results</li> <li>understand how parameters affect the built pangenome graphs</li> </ul>"},{"location":"pangenome_graph_construction/#getting-started","title":"Getting started","text":"<p>NeSI HPC environment is used for the analysis. Please make sure to have a NeSI account and you are able to login.</p>"},{"location":"pangenome_graph_construction/#setting-up-your-project-directory-and-download-the-datasets","title":"Setting up your project directory and download the datasets","text":"<pre><code># Create a new directory in somewhere and change to that directory\nmkdir pg_workshop\ncd pg_workshop\n# Keep a note of the absolute path of your directory\npwd\n/home/zyang/pg_worhshop\n\n# Downloading and preparing datasets\ngit clone https://github.com/ZoeYang2020/dataset_for_pg_workshop\n\n# copy the 4Sim.fa dataset to your work directory, mine is /home/zyang/pg_worhshop\ncp /home/zyang/pg_worhshop/dataset_for_pg_workshop/datasets_for_PangenomeGraphConstruction_pg_workshop/4Sim.fa /home/zyang/pg_worhshop\n\n# go back to your work directory \ncd /home/zyang/pg_worhshop\n</code></pre>"},{"location":"pangenome_graph_construction/#construct-pangenome-graph-for-the-4sim-genomes","title":"Construct pangenome graph for the 4Sim genomes","text":"<pre><code>#Creating an index for the seqence file using samtools and check\n#In Nesi environment you will have to load the samtools module first\nmodule purge\nmodule load SAMtools/1.16.1-GCC-11.3.0\nsamtools faidx 4Sim.fa\nless -S 4Sim.fa.fai\nNC_017518       2248966 16      60      61\nST41Sim 2249014 2286474 2249014 2249015\nST154Sim        2248965 4535499 2248965 2248966\nST42Sim 2249050 6784474 2249050 2249051\n</code></pre>"},{"location":"pangenome_graph_construction/#executing-pggb-tool-using-singularity-container","title":"Executing <code>pggb</code> tool using Singularity container","text":"<pre><code>module purge\nmodule load Singularity\ncontainer=/nesi/project/nesi02659/software/pggb/pggb_0.5.3.simg\n\n# Execute singularity exec ${container} pggb to check the command list of PGGB\nsingularity exec ${container} pggb ERROR: mandatory arguments -i and -n\nERROR: -n must be greater than or equal to 2\nusage: /usr/local/bin/pggb -i &lt;input-fasta&gt; -n &lt;n-haplotypes&gt; [options]\noptions:\n   [wfmash]\n-i, --input-fasta FILE      input FASTA/FASTQ file\n    -s, --segment-length N      segment length for mapping [default: 5000]\n-l, --block-length N        minimum block length filter for mapping [default: 5*segment-length]\n-p, --map-pct-id PCT        percent identity for mapping/alignment [default: 90]\n-n, --n-haplotypes N        number of haplotypes\n    -N, --no-split              disable splitting of input sequences during mapping [default: enabled]\n-x, --sparse-map N          keep this fraction of mappings ('auto' for giant component heuristic) [default: 1.0]\n-K, --mash-kmer N           kmer size for mapping [default: 19]\n-F, --mash-kmer-thres N     ignore the top % most-frequent kmers [default: 0.001]\n-Y, --exclude-delim C       skip mappings between sequences with the same name prefix before\n                                the given delimiter character [default: all-vs-all and !self]\n[seqwish]\n-k, --min-match-len N       filter exact matches below this length [default: 19]\n-f, --sparse-factor N       keep this randomly selected fraction of input matches [default: no sparsification]\n-B, --transclose-batch      number of bp to use for transitive closure batch [default: 10000000]\n[smoothxg]\n-X, --skip-normalization    do not normalize the final graph [default: normalize the graph]\n-H, --n-haplotypes-smooth N number of haplotypes, if different than that set with -n [default: -n]\n-j, --path-jump-max         maximum path jump to include in block [default: 0]\n-e, --edge-jump-max N       maximum edge jump before breaking [default: 0]\n-G, --poa-length-target N,M target sequence length for POA, one per pass [default: 700,900,1100]\n-P, --poa-params PARAMS     score parameters for POA in the form of match,mismatch,gap1,ext1,gap2,ext2\n                                may also be given as presets: asm5, asm10, asm15, asm20\n                                [default: 1,19,39,3,81,1 = asm5]\n-O, --poa-padding N         pad each end of each sequence in POA with N*(mean_seq_len) bp [default: 0.001]\n-d, --pad-max-depth N       depth/haplotype at which we don't pad the POA problem [default: 100]\n    -b, --run-abpoa             run abPOA [default: SPOA]\n    -z, --global-poa            run the POA in global mode [default: local mode]\n    -M, --write-maf             write MAF output representing merged POA blocks [default: off]\n    -Q, --consensus-prefix P    use this prefix for consensus path names [default: Consensus_]\n   [odgi]\n    -v, --skip-viz              don't render visualizations of the graph in 1D and 2D [default: make them]\n-S, --stats                 generate statistics of the seqwish and smoothxg graph [default: off]\n[vg]\n-V, --vcf-spec SPEC         specify a set of VCFs to produce with SPEC = REF:DELIM[:LEN][,REF:DELIM:[LEN]]*\n                                the paths matching ^REF are used as a reference, while the sample haplotypes\n                                are derived from path names, e.g. when DELIM=# and with '-V chm13:#',\na path named HG002#1#ctg would be assigned to sample HG002 phase 1.\n                                If LEN is specified and greater than 0, the VCFs are decomposed, filtering\n                                sites whose max allele length is greater than LEN. [default: off]\n[multiqc]\n-m, --multiqc               generate MultiQC report of graphs' statistics and visualizations,\n                                automatically runs odgi stats [default: off]\n[general]\n-o, --output-dir PATH       output directory\n    -D, --temp-dir PATH         directory for temporary files\n    -a, --input-paf FILE        input PAF file; the wfmash alignment step is skipped\n    -r, --resume                do not overwrite existing outputs in the given directory\n                                [default: start pipeline from scratch]\n-t, --threads N             number of compute threads to use in parallel steps [default: 72]\n-T, --poa-threads N         number of compute threads to use during POA (set lower if you OOM during smoothing)\n-A, --keep-temp-files       keep intermediate graphs\n    -Z, --compress              compress alignment (.paf), graph (.gfa, .og), and MSA (.maf) outputs with pigz,\n                                and variant (.vcf) outputs with bgzip\n    --version                   display the version of pggb\n    -h, --help                  this text\n\nUse wfmash, seqwish, smoothxg, odgi, gfaffix, and vg to build, project and display a pangenome graph.\n</code></pre>"},{"location":"pangenome_graph_construction/#key-parameters-for-executing-pggb","title":"key parameters for executing PGGB","text":"<p>https://github.com/pangenome/pggb The overall structure of pggb's output graph is defined by three parameters: genome number (-n), segment length (-s), and pairwise identity (-p). </p> <p>Genome number (-n) is a given, but varies in ways that are difficult to infer and is thus left up to the user. Segment length defines the seed length used by the \"MashMap3\" homology mapper in wfmash. </p> <p>The pairwise identity (-p) is the minimum allowed pairwise identity between seeds, which is estimated using a mash-type approximation based on k-mer Jaccard. Mappings are initiated from collinear chains of around 5 seeds (-l, --block-length), and extended greedily as far as possible, allowing up to -n minus 1 mappings at each query position.</p> <p>An additional parameter, -k, can also greatly affect graph structure by pruning matches shorter than a given threshold from the initial graph model. In effect, -k N removes any match shorter than Nbp from the initial alignment. This filter removes potentially ambiguous pairwise alignments from consideration in establishing the initial scaffold of the graph.</p> <p>The initial graph is defined by parameters to wfmash and seqwish. But due to the ambiguities generated across the many pairwise alignments we use as input, this graph can be locally very complex. To regularize it we orchestrate a series of graph transformations. First, with smoothxg, we \"smooth\" it by locally realigning sequences to each other with a traditional multiple sequence alignment (we specifically apply POA). This process repeats multiple times to smooth over any boundary effects that may occur due to binning errors near MSA boundaries. Finally, we apply gfaffix to remove forks where both alternatives have the same sequence.</p>"},{"location":"pangenome_graph_construction/#examples-of-key-parameters-for-executing-pggb","title":"examples of key parameters for executing PGGB","text":"<ul> <li>Human, whole genome, 90 haplotypes: pggb -p 98 -s 50k -n 90 -k 79 ...</li> <li>15 helicobacter genomes, 5% divergence: pggb -n 15 -k 79, and 15 at higher (10%) divergence pggb -n 15 -k 19 -P asm20 ...</li> <li>Yeast genomes, 5% divergence: pggb's defaults should work well, just set -n.</li> <li>Aligning 9 MHC class II assemblies from vertebrate genomes (5-10% divergence): pggb -n 9 -k 29 ...</li> <li>A few thousand bacterial genomes pggb -x auto -n 2146 .... In general mapping sparsification (-x auto) is a good idea when you have many hundreds to thousands of genomes.</li> <li>pggb defaults to using the number of threads as logical processors on the system (the thread count given by getconf _NPROCESSORS_ONLN). Use -t to set an appropriate level of parallelism if you can't use all the processors on your system.</li> </ul>"},{"location":"pangenome_graph_construction/#other-parameters-for-executing-pggb","title":"other parameters for executing PGGB","text":"<p>-S generate statistics of the seqwish and smoothxg graph</p> <p>-m generate MultiQC report of graphs' statistics and visualizations, automatically runs odgi stats</p> <p>-V specify a set of VCFs to produce with SPEC = REF:DELIM[:LEN][,REF:DELIM:[LEN]]* the paths matching ^REF are used as a reference, while the sample haplotype are derived from path names, e.g. when DELIM=# and with '-V chm13:#', a path named HG002#1#ctg would be assigned to sample HG002 phase 1. If LEN is specified and greater than 0, the VCFs are decomposed, filtering sites whose max allele length is greater than LEN. [default: off]</p> <p>-o, --output-dir PATH       output directory</p>"},{"location":"pangenome_graph_construction/#use-mash-triangle-to-check-the-pairwise-identity-of-the-input-genomes-which-will-give-us-some-idea-how-to-set-p","title":"Use mash triangle to check the pairwise identity of the input genomes, which will give us some idea how to set -p","text":"<pre><code>module purge\nmodule load Mash/2.3-GCC-11.3.0\nmash triangle 4Sim.fa &gt;4Sim.fa_mash\nless -S 4Sim.fa_mash\n        4\nNC_017518\nST41Sim 0.0010072\nST154Sim        0.00121124      0.000830728\nST42Sim 0.00251903      0.00366686      0.00375609\n</code></pre>"},{"location":"pangenome_graph_construction/#construct-pangenome-graph-for-4sim-genomes-with-singularity-container-pggb-k-1000-p-96","title":"construct pangenome graph for 4Sim genomes with Singularity container PGGB, -k 1000, -p 96","text":"<pre><code>module purge\nmodule load Singularity\ncontainer=/nesi/project/nesi02659/software/pggb/pggb_0.5.3.simg\n\n# Execute singularity exec ${container} pggb, set -s 1000\nsingularity exec ${container} pggb -i 4Sim.fa -s 1000 -p 96 -n 4 -t 24 -S -m -o 4Sim_1K96 -V 'NC_017518:#'\n</code></pre>"},{"location":"pangenome_graph_construction/#executing-pggb-as-a-slurm-job","title":"Executing <code>pggb</code> as a SLURM Job","text":"<p>Executing shell scripts in the Nesi environment might not be the best way to handle larger files which will require large memory, CPU power and time. We can modify the previusely explained script as below to run as SLURM job. Note the additional parameters specified by <code>#SBATCH</code> which will indicate maximum resource limitations. </p>"},{"location":"pangenome_graph_construction/#pggb_slurm_1k96_4simsh","title":"pggb_slurm_1K96_4Sim.sh","text":"<p><pre><code>#!/bin.bash\n#SBATCH --account       ga03793\n#SBATCH --job-name      4Sim_1K96\n#SBATCH --cpus-per-task 8\n#SBATCH --mem           4G\n#SBATCH --time          1:00:00\nmodule purge\nmodule load Singularity\n\n#export container to a variable for convenience\nWD=/home/zyang/pg_workshop #Working Directory\ncontainer=/nesi/project/nesi02659/software/pggb/pggb_0.5.3.simg\ndata=/home/zyang/pg_workshop/4Sim.fa\noutput=/home/zyang/pg_workshop\n\n#Bind filesystem to container image\nexport SINGULARITY_BIND=\"${WD}, /nesi/project/nesi02659/\"\nsingularity exec ${container} pggb -i $data -s 1000 -p 96 -n 4 -t 24 -S -m -o $output/4Sim_1K96 -V 'NC_017518:#'\n</code></pre> The job can be submitted using the <code>sbatch</code> command it will show a job id.</p>"},{"location":"pangenome_graph_construction/#pggb_slurm_10k96_4simsh","title":"pggb_slurm_10K96_4Sim.sh","text":"<pre><code>#!/bin.bash\n#SBATCH --account       ga03793\n#SBATCH --job-name      4Sim_10K96\n#SBATCH --cpus-per-task 8\n#SBATCH --mem           4G\n#SBATCH --time          1:00:00\nmodule purge\nmodule load Singularity\n\n#export container to a variable for convenience\nWD=/home/zyang/pg_workshop #Working Directory\ncontainer=/nesi/project/nesi02659/software/pggb/pggb_0.5.3.simg\ndata=/home/zyang/pg_workshop/4Sim.fa\noutput=/home/zyang/pg_workshop\n\n#Bind filesystem to container image\nexport SINGULARITY_BIND=\"${WD}, /nesi/project/nesi02659/\"\nsingularity exec ${container} pggb -i $data -s 10000 -p 96 -n 4 -t 24 -S -m -o $output/4Sim_10K96 -V 'NC_017518:#'\n</code></pre>"},{"location":"pangenome_graph_construction/#pggb_slurm_10k96_k79_4simsh","title":"pggb_slurm_10K96_K79_4Sim.sh","text":"<pre><code>#!/bin.bash\n#SBATCH --account       ga03793\n#SBATCH --job-name      4Sim_1K96_K79\n#SBATCH --cpus-per-task 8\n#SBATCH --mem           4G\n#SBATCH --time          1:00:00\nmodule purge\nmodule load Singularity\n\n#export container to a variable for convenience\nWD=/home/zyang/pg_workshop #Working Directory\ncontainer=/nesi/project/nesi02659/software/pggb/pggb_0.5.3.simg\ndata=/home/zyang/pg_workshop/4Sim.fa\noutput=/home/zyang/pg_workshop\n\n#Bind filesystem to container image\nexport SINGULARITY_BIND=\"${WD}, /nesi/project/nesi02659/\"\nsingularity exec ${container} pggb -i $data -s 1000 -p 96 -n 4 -K 79 -t 24 -S -m -o $output/4Sim_1K96_K79 -V 'NC_017518:#'\n</code></pre>"},{"location":"pangenome_graph_construction/#evaluate-pangenome-graphs-for-4sim-genomes-constructed-with-different-settings","title":"Evaluate Pangenome Graphs for 4Sim Genomes Constructed with Different Settings","text":"<ul> <li> <p>We have employed three distinct settings to construct the pangenome graph of the 4Sim genomes. Which setting yielded the most optimal result? How can we determine this? </p> </li> <li> <p>download the multiqc.html file, check the Detailed ODGI stats table.</p> </li> </ul>"},{"location":"pangenome_graph_construction/#1k96","title":"1k96","text":"Sample Name Length Nodes Edges Components A C T G N seqwish 2280344 22216 29823 4 1 551639 578590 557450 592665 smooth 2261163 29965 40179 4 1 548754 574693 551650 586066"},{"location":"pangenome_graph_construction/#1k96-k79","title":"1k96,-K79","text":"Sample Name Length Nodes Edges Components A C T G N seqwish 2279905 22209 29812 4 1 551588 578459 557291 592567 smooth 2261401 29976 40199 4 1 553049 580469 547460 580423"},{"location":"pangenome_graph_construction/#10k96","title":"10k96","text":"Sample Name Length Nodes Edges Components A C T G N seqwish 2340700 22166 29759 4 1 566559 594741 571836 607564 smooth 2319601 29888 40070 4 1 566755 599287 562078 591481"},{"location":"pangenome_graph_construction/#vg-deconstruct-graph-to-get-the-variations-in-vcf","title":"vg deconstruct graph to get the variations in vcf","text":"<pre><code>mkdir vg_deconstruct\n#copy gfa to vg_deconsturct and rename the gfa files with its PGGB settings\ncp /home/zyang/pg_workshop/4Sim_1K96/4Sim.fa.97e7156.417fcdf.7659dc8.smooth.final.gfa /home/zyang/pg_workshop/vg_deconstruct/4Sim_1K96.gfa\ncp /home/zyang/pg_workshop/4Sim_1K96_K79/4Sim.fa.f958389.417fcdf.7659dc8.smooth.final.gfa /home/zyang/pg_workshop/vg_deconstruct/4Sim_1K96_K79.gfa\n\ncd /home/zyang/pg_workshop/vg_deconstruct\n\nmodule purge\nmodule load vg/1.46.0\nmodule load BCFtools/1.16-GCC-11.3.0\n\nvg deconstruct -p NC_017518  -a -e 4Sim_1K96.gfa &gt;4Sim_1K96_aep1.vcf\nbcftools stats 4Sim_1K96_aep1.vcf &gt;4Sim_1K96_aep1.vcf_stats\n</code></pre>"},{"location":"pangenome_graph_construction/#4sim_vg_deconstructsh","title":"4Sim_vg_deconstruct.sh","text":"<pre><code>#!/usr//bin/bash\n#SBATCH --account       ga03793\n#SBATCH --job-name      4Sim_vg_deconstruct\n#SBATCH --cpus-per-task 8\n#SBATCH --mem           4G\n#SBATCH --time          1:00:00\nmodule purge\nmodule load vg/1.46.0\nmodule load BCFtools/1.16-GCC-11.3.0\n\nexport container to a variable for convenience\ninputGFA=/home/zyang/pg_workshop/vg_deconstruct/*.gfa\ninput_folder=/home/zyang/pg_workshop/vg_deconstruct\noutput=/home/zyang/pg_workshop/vg_deconstruct\n\nfor f in $inputGFA\ndo\nx=$(basename $f .gfa)\necho ${x}\nvg deconstruct -p NC_017518  -a -e $input_folder/${x}.gfa &gt; $output/${x}aep1.vcf\nbcftools stats $output/${x}aep1.vcf &gt;$output/${x}aep1.vcf_stats\ndone\n</code></pre>"},{"location":"pangenome_graph_construction/#bcftools-isec-to-check-the-overlap-of-the-1k96-k-19-1k96-k-79","title":"bcftools isec to check the overlap of the 1k96 -K 19, 1k96, -K 79","text":"<pre><code>#!/bin.bash\n#SBATCH --account       ga03793\n#SBATCH --job-name      4Sim_1k96_isec\n#SBATCH --cpus-per-task 8\n#SBATCH --mem           4G\n#SBATCH --time          1:00:00\nmodule purge\nmodule load BCFtools/1.16-GCC-11.3.0\n\ninput_folder=/home/zyang/pg_workshop/vg_deconstruct\noutput_folder=/home/zyang/pg_workshop/vg_deconstruct\n\nbcftools view $input_folder/4Sim_1K96aep1.vcf  -Oz -o $output_folder/4Sim_1K96aep1.vcf.gz\nbcftools view $input_folder/4Sim_1K96_K79aep1.vcf -Oz -o $output_folder/4Sim_1K96_K79aep1.vcf.gz\n\nbcftools index $output_folder/4Sim_1K96aep1.vcf.gz\nbcftools index $output_folder/4Sim_1K96_K79aep1.vcf.gz\n\nbcftools isec $output_folder/4Sim_1K96aep1.vcf.gz $output_folder/4Sim_1K96_K79aep1.vcf.gz -p $output_folder/isec_4Sim_1K96\n</code></pre> <pre><code>#specific to  1k96 -K 19\nless -S /home/zyang/pg_workshop/vg_deconstruct/isec_4Sim_1K96/0000.vcf\n#specific to  1k96 -K 79\nless -S /home/zyang/pg_workshop/vg_deconstruct/isec_4Sim_1K96/0001.vcf\n</code></pre>"},{"location":"pangenome_graph_construction/#difference-between-1k96-k-19-vs-1k96-k-79","title":"difference between 1k96 -K 19 Vs 1k96 -K 79","text":""},{"location":"pangenome_graph_construction/#pgge","title":"PGGE","text":"<p>This pangenome graph evaluation pipeline measures the reconstruction accuracy of a pangenome graph (in the variation graph model). Its goal is to give guidance in finding the best pangenome graph construction tool for a given input data and task.</p> <pre><code>mkdir 4Sim_pgge\n#copy *.gfa to 4Sim_pgge\ncp /home/zyang/pg_workshop/vg_deconstruct/*.gfa /home/zyang/pg_workshop/4Sim_pgge\ncp /home/zyang/pg_workshop/4Sim_10K96/4Sim.fa.e7f7fe6.417fcdf.7659dc8.smooth.final.gfa /home/zyang/pg_workshop/4Sim_pgge/4Sim_10K96.gfa\n</code></pre>"},{"location":"pangenome_graph_construction/#pgge-script","title":"PGGE script","text":"<pre><code>#!/bin.bash\n#SBATCH --account       ga03793\n#SBATCH --job-name      4Sim_pgge\n#SBATCH --cpus-per-task 8\n#SBATCH --mem           4G\n#SBATCH --time          1:00:00\nmodule purge\nmodule load Singularity\n\n#export container to a variable for convenience\ncontainer=/nesi/project/nesi02659/software/pgge/pgge_032023.simg\n\nWD=/home/zyang/pg_workshop/4Sim_pgge #Working Directory\ninputGFA=/home/zyang/pg_workshop/4Sim_pgge/*.gfa\ninput_folder=/home/zyang/pg_workshop/4Sim_pgge\ninputfa=/home/zyang/pg_workshop/4Sim.fa\noutput=/home/zyang/pg_workshop/4Sim_pgge\nbeehave=/home/zyang/pg_workshop/beehave.R\n\n#Bind filesystem to container image\nexport SINGULARITY_BIND=\"${WD}, /nesi/project/nesi02659/\"\nfor x in $inputGFA\ndo\nsingularity exec ${container} pgge -g $x -f $inputfa -o $output -r $beehave -b $output/pgge_4Sim_peanut_bed -l 100000 -s 5000 -t 16\ndone\n</code></pre>"},{"location":"pangenome_graph_construction/#odgi-paths-to-extract-distance","title":"ODGI paths to extract distance","text":"<pre><code>mkdir odgi_distance\ncp odgi_distance\n#copy gfa to odgi_distance working directory \ncp /home/zyang/pg_workshop/vg_deconstruct/4Sim_1K96.gfa /home/zyang/pg_workshop/odgi_distance/\n\nmodule purge\nmodule load Singularity\ncontainer=/nesi/project/nesi02659/software/odgi/odgi_0.8.2.simg\nsingularity exec ${container} odgi paths -i 4Sim_1K96.gfa -d -D 'AAAA' &gt;4Sim_1K96.gfa_distance\ncut -f 1,2,6 4Sim_1K96.gfa_distance &gt;4Sim_1K96.gfa_distance_cut\n</code></pre>"},{"location":"pangenome_graph_construction/#script-for-odgi-paths-to-extract-distance","title":"script for ODGI paths to extract distance","text":"<pre><code>#!/bin.bash\n#SBATCH --account       ga03793\n#SBATCH --job-name      4Sim_1K96_distance\n#SBATCH --cpus-per-task 8\n#SBATCH --mem           4G\n#SBATCH --time          1:00:00\nmodule purge\nmodule load Singularity\n\n#export container to a variable for convenience\ncontainer=/nesi/project/nesi02659/software/odgi/odgi_0.8.2.simg\ndata=/home/zyang/pg_workshop/odgi_distance/4Sim_1K96.gfa\noutput=/home/zyang/pg_workshop/odgi_distance\n\nsingularity exec ${container} odgi paths -i $data -d -D 'AAAA' &gt;$output/4Sim_1K96.gfa_distance\ncut -f 1,2,6 $output/4Sim_1K96.gfa_distance &gt;$output/4Sim_1K96.gfa_distance_cut\n</code></pre>"},{"location":"pangenome_graph_construction/#r-script-for-clustering-based-on-distance-among-paths-of-a-graph-4sim-1k96","title":"R script for clustering based on distance among paths of a graph, 4Sim 1k96","text":"<p>list2dist_clustering_4Sim.R <pre><code>setwd(\"/home/zyang/pg_workshop/odgi_distance\")\nlibrary(reshape)\nlibrary(ape)\n# read in the data\ndat=read.csv(\"4Sim_1K96.gfa_distance_cut\",sep=\"\\t\")\ndat\n# use reshape's cast function to change to matrix\nm &lt;- cast(dat, group.a ~ group.b)\nm\n# set the row names\nrownames(m) &lt;- m[,1]\nrownames(m)\n#The fellowing two lines code will cause no IDs in the clustering\n# get rid of a couple of rows\n#m &lt;- m[,-2]\n# convert any 0s that were read in as strings to integers\n#m &lt;- apply(m, 2, as.numeric )\nm\n\n# change the matrix to a distance matrix\nd &lt;- dist(m)\nd\n\n# do hierarchical clustering\nh &lt;- hclust(d)\nh\n# plot the dendrogram\nplot(h)\n# use ape's as phylo function\ntree &lt;- as.phylo(h)\n# export as newick for viewing in figtree\nwrite.tree(phy=tree, file = '4Sim_1k96_distance.tree')\n</code></pre></p>"},{"location":"pangenome_graph_construction/#run-the-r-script-for-clustering-based-on-distance-on-nesi","title":"run the R script for clustering based on distance on Nesi","text":"<pre><code>#!/bin.bash\n#SBATCH --account       ga03793\n#SBATCH --job-name      4Sim_1K96_distance_clustering\n#SBATCH --cpus-per-task 8\n#SBATCH --mem           4G\n#SBATCH --time          1:00:00\nmodule purge\nmodule load R/4.0.1-gimkl-2020\n\nRscript 8_list2dist_clustering_4Sim.R\n</code></pre>"},{"location":"pangenome_graph_construction/#construct-pangenome-graph-for-the-3st-genomes","title":"Construct pangenome graph for the 3ST genomes","text":""},{"location":"pangenome_graph_construction/#prepare-dataset-and-build-index","title":"prepare dataset and build index","text":"<pre><code># copy the 3ST.fa dataset to your work directory, mine is /home/zyang/pg_worhshop\ncp /home/zyang/pg_workshop/dataset_for_pg_workshop/datasets_for_PangenomeGraphConstruction_pg_workshop/3ST.fa /home/zyang/pg_workshop\n\n# go back to your work directory \ncd /home/zyang/pg_worhshop\n\n#build index for 3ST.fa\nmodule purge\nmodule load SAMtools/1.16.1-GCC-11.3.0\nsamtools faidx 3ST.fa\n\n#check index \nless -S 3ST.fa.fai\nNC_017518       2248966 77      60      61\nST41    2217832 2286541 60      61\nST154   2233582 4541354 60      61\n</code></pre>"},{"location":"pangenome_graph_construction/#use-mash-triangle-to-check-the-pairwise-identity-of-the-input-genomes-which-will-give-us-some-idea-how-to-set-p_1","title":"Use mash triangle to check the pairwise identity of the input genomes, which will give us some idea how to set -p","text":"<pre><code>module purge\nmodule load Mash/2.3-GCC-11.3.0\nmash triangle 4Sim.fa &gt;4Sim.fa_mash\nless -S 3ST.fa_mash\n        3\nNC_017518\nST41    0.00146992\nST154   0.00165343      0.00131423\n</code></pre>"},{"location":"pangenome_graph_construction/#check-the-mauve-aligment-of-3st","title":"check the Mauve aligment of 3ST","text":"<p>Mauve alignments demonstrated large inversions among the 3ST genomes.  </p>"},{"location":"pangenome_graph_construction/#pggb_slurm_2k95_3stsh-k-2000-p-95","title":"pggb_slurm_2K95_3ST.sh, -k 2000, -p 95","text":"<pre><code>#!/bin.bash\n#SBATCH --account       ga03793\n#SBATCH --job-name      3ST_2K95\n#SBATCH --cpus-per-task 8\n#SBATCH --mem           4G\n#SBATCH --time          1:00:00\nmodule purge\nmodule load Singularity\n\n#export container to a variable for convenience\ncontainer=/nesi/project/nesi02659/software/pggb/pggb_0.5.3.simg\ndata=/home/zyang/pg_workshop/3ST.fa\noutput=/home/zyang/pg_workshop\n\nsingularity exec ${container} pggb -i $data -s 2000 -p 95 -n 3 -t 24 -S -m -o $output/3ST_2K95 -V 'NC_017518:#'\n</code></pre>"},{"location":"pangenome_graph_construction/#construct-pangenome-graph-for-the-24nm-genomes","title":"Construct pangenome graph for the 24NM genomes","text":""},{"location":"pangenome_graph_construction/#prepare-dataset-and-build-index_1","title":"prepare dataset and build index","text":"<pre><code># copy the 24NM.fa.gz dataset to your work directory, mine is /home/zyang/pg_worhshop\ncp /home/zyang/pg_workshop/dataset_for_pg_workshop/datasets_for_PangenomeGraphConstruction_pg_workshop/24NM.fa.gz /home/zyang/pg_workshop\n\n# go back to your work directory \ncd /home/zyang/pg_worhshop\n\n#uncompress 24NM.fa.gz\ngzip -d 24NM.fa.gz\n\n#build index for 24NM.fa\nmodule purge module load SAMtools/1.16.1-GCC-11.3.0\nsamtools faidx 24NM.fa\n\n#check index \nless -S 24NM.fa.fai\nNC_003112.2     2272360 60      60      61\nNC_003116.1     2184406 2310354 60      61\nNC_008767.1     2194961 4531228 60      61\nNC_010120.1     2153416 6762834 60      61\nNC_017501.1     2277550 8952201 60      61\nNC_013016.1     2145295 11267774        60      61\nNC_017505.1     2242947 13448888        60      61\nNC_017513.1     2184862 15729279        60      61\nNC_017514.1     2223518 17950622        60      61\nNC_017515.1     2250449 20211265        60      61\nNC_017512.1     2227255 22499286        60      61\nNZ_CP012392.1   2170619 24763743        60      61\nNZ_CP016627.1   2173408 26970619        60      61\nNZ_CP016646.1   2173686 29180331        60      61\nNZ_CP016682.1   2175832 31390326        60      61\nNZ_CP020402.2   2305818 33602508        60      61\nNZ_CP031334.1   2314390 35946837        60      61\nNZ_CP031324.1   2291778 38299881        60      61\nNZ_CP031328.1   2223855 40629936        60      61\nNZ_CP031333.1   2280611 42890936        60      61\nNZ_CP021517.1   2167947 45209638        60      61\nNC_017518       2248966 47413790        60      61\nST41    2217832 49700245        60      61\nST154   2233582 51955048        60      61\n</code></pre>"},{"location":"pangenome_graph_construction/#use-mash-triangle-to-check-the-pairwise-identity-of-the-input-genomes-which-will-give-us-some-idea-how-to-set-p_2","title":"Use mash triangle to check the pairwise identity of the input genomes, which will give us some idea how to set -p","text":"<pre><code>module purge\nmodule load Mash/2.3-GCC-11.3.0\nmash triangle 24NM.fa &gt;24NM.fa_mash\nless -S 24NM.fa_mash\n\n24\nNC_003112.2\nNC_003116.1     0.0188675\nNC_008767.1     0.0174175       0.0171844\nNC_010120.1     0.0184965       0.0166683       0.0166117\nNC_017501.1     0.0181313       0.0181313       0.016782        0.0190552\nNC_013016.1     0.0218499       0.0190552       0.0171844       0.0191812       0.0188053\nNC_017505.1     0.015943        0.0191812       0.0168963       0.0187432       0.0175939       0.0212923\nNC_017513.1     0.0186195       0.0175939       0.00861543      0.0167251       0.016782        0.0174175       0.0169536\nNC_017514.1     0.0154006       0.0185579       0.0167251       0.0185579       0.0172424       0.0204123       0.00977265      0.0175939\nNC_017515.1     0.0115313       0.0177716       0.0157245       0.0170111       0.0168391       0.0202137       0.016782        0.0155619       0.0158335\nNC_017512.1     0.0192445       0.00594242      0.0177716       0.0173006       0.0184965       0.0200822       0.0202137       0.0182524       0.0199514       0.0179508\nNZ_CP012392.1   0.0183741       0.0171844       0.017359        0.0172424       0.0183132       0.0204789       0.0180108       0.0170111       0.0172424       0.0162193       0.0177716\nNZ_CP016627.1   0.0181313       0.0174175       0.00279888      0.0166117       0.0172424       0.0179508       0.0175349       0.00877107      0.0171265       0.0166683       0.017359\nNZ_CP016646.1   0.0178909       0.0172424       0.0163866       0.0171265       0.0174761       0.0184352       0.0189925       0.0163307       0.017653        0.0165552       0.0177716\nNZ_CP016682.1   0.0180108       0.0170111       0.0162193       0.0169536       0.0171844       0.0181313       0.0189299       0.0164427       0.0175939       0.0162749       0.0175349\nNZ_CP020402.2   0.0196919       0.0188675       0.0177122       0.0180709       0.0134525       0.0185579       0.0171844       0.0171265       0.0170111       0.0182524       0.0199514\nNZ_CP031334.1   0.0170111       0.0180709       0.0156702       0.0163866       0.0147145       0.0183132       0.0165552       0.0149759       0.0164427       0.0152936       0.0191181\nNZ_CP031324.1   0.0177716       0.0189925       0.0166683       0.0181313       0.0146626       0.0193079       0.0178909       0.0161637       0.0166117       0.0160531       0.0194991\nNZ_CP031328.1   0.0181313       0.0180108       0.0168391       0.0174175       0.0162749       0.0196275       0.0182524       0.0166683       0.0157789       0.0168391       0.0184965\nNZ_CP031333.1   0.0117112       0.0172424       0.0158335       0.0170687       0.0168391       0.0201478       0.016782        0.0156702       0.0158335       0.00186568      0.0171844\nNZ_CP021517.1   0.0178312       0.0163866       0.0171265       0.0165552       0.0180709       0.0194352       0.0178909       0.0165552       0.0174761       0.0158335       0.0170687\nNC_017518       0.0152404       0.0186195       0.0166117       0.0183741       0.016782        0.0200167       0.00916565      0.0174761       0.001839        0.015508        0.0194991\nST41    0.0150813       0.0184352       0.0164427       0.0183132       0.0170687       0.0201478       0.00912584      0.017653        0.00128842      0.0158335       0.0194991       0.\nST154   0.0151872       0.0182524       0.0164989       0.0182524       0.0171265       0.0200167       0.00952763      0.0173006       0.00175922      0.0156702       0.0193714       0.\n</code></pre>"},{"location":"pangenome_graph_construction/#pggb_slurm_2k95_3stsh-k-2000-p-95_1","title":"pggb_slurm_2K95_3ST.sh, -k 2000, -p 95","text":"<pre><code>#!/bin.bash\n#SBATCH --account       ga03793\n#SBATCH --job-name      24NM_10k95\n#SBATCH --cpus-per-task 8\n#SBATCH --mem           4G\n#SBATCH --time          3:00:00\nmodule purge\nmodule load Singularity\n\n#export container to a variable for convenience\nWD=/home/zyang/pg_workshop #Working Directory\ncontainer=/nesi/project/nesi02659/software/pggb/pggb_0.5.3.simg\ndata=/home/zyang/pg_workshop/24NM.fa\noutput=/home/zyang/pg_workshop\n\n#Bind filesystem to container image\nexport SINGULARITY_BIND=\"${WD}, /nesi/project/nesi02659/\"\nsingularity exec ${container} pggb -i $data -s 10000 -p 95 -n 24 -t 24 -S -m -o $output/24NM_10K95 -V 'NC_017518:#'\n</code></pre>"},{"location":"pangenome_graph_construction/#pggb_slurm_2k95_3stsh-k-2000-p-95-x","title":"pggb_slurm_2K95_3ST.sh, -k 2000, -p 95, -x","text":"<pre><code>#!/bin.bash\n#SBATCH --account       ga03793\n#SBATCH --job-name      24NM_10k95_X\n#SBATCH --cpus-per-task 8\n#SBATCH --mem           4G\n#SBATCH --time          3:00:00\nmodule purge\nmodule load Singularity\n\n#export container to a variable for convenience\nWD=/home/zyang/pg_workshop #Working Directory\ncontainer=/nesi/project/nesi02659/software/pggb/pggb_0.5.3.simg\ndata=/home/zyang/pg_workshop/24NM.fa\noutput=/home/zyang/pg_workshop\n\n#Bind filesystem to container image\nexport SINGULARITY_BIND=\"${WD}, /nesi/project/nesi02659/\"\nsingularity exec ${container} pggb -i $data -s 10000 -p 95 -n 24 -x auto -t 24 -S -m -o $output/24NM_10K95x -V 'NC_017518:#'\n</code></pre>"},{"location":"preparing_data_files/","title":"Preparing required data files with simuG tool","text":"<p>simuG is a light-weighted tool which can be used to simulate sequences with pre-defined number of random genomic variants against a reference sequence (Please refer the Git Page for more details). The following example demostrates generating three new sequence using known SNP and INDEL counts.</p>"},{"location":"preparing_data_files/#1-setting-up-the-tool","title":"1. Setting up the tool","text":"<p>Please refer the installation instruction in the Git Page. <pre><code>git clone https://github.com/yjx1217/simuG.git\ncd simuG\nperl simuG.pl -h\nperl vcf2model.pl -h\n</code></pre></p>"},{"location":"preparing_data_files/#2-data-source","title":"2. Data source","text":"<p>You can download the reference sequence (Neisseria gonorrhoeae FA 1090 genome assembly) from the site Genome assembly ASM19152v1 and get the file ncbi_dataset/data/GCF_000191525.1/GCF_000191525.1_ASM19152v1_genomic.fna from he zip file GCF_000191525.1.zip. Rename it as \"ref.fa\" to refere easily in next steps. </p> <p>In Unix environment you can use <code>curl</code>. </p> <pre><code>$ curl -OJX GET \"https://api.ncbi.nlm.nih.gov/datasets/v2alpha/genome/accession/GCF_000191525.1/download?include_annotation_type=GENOME_FASTA,GENOME_GFF,RNA_FASTA,CDS_FASTA,PROT_FASTA,SEQUENCE_REPORT&amp;filename=GCF_000191525.1.zip\" -H \"Accept: application/zip\"\n% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 1807k    0 1807k    0     0   294k      0 --:--:--  0:00:06 --:--:--  421k\n\n$ ls\nGCF_000191525.1.zip\n\n$ unzip GCF_000191525.1.zip Archive:  GCF_000191525.1.zip\n  inflating: README.md               inflating: ncbi_dataset/data/assembly_data_report.jsonl  inflating: ncbi_dataset/data/GCF_000191525.1/GCF_000191525.1_ASM19152v1_genomic.fna  inflating: ncbi_dataset/data/GCF_000191525.1/genomic.gff  inflating: ncbi_dataset/data/GCF_000191525.1/cds_from_genomic.fna  inflating: ncbi_dataset/data/GCF_000191525.1/protein.faa  inflating: ncbi_dataset/data/GCF_000191525.1/sequence_report.jsonl  inflating: ncbi_dataset/data/dataset_catalog.json  $ cp ncbi_dataset/data/GCF_000191525.1/GCF_000191525.1_ASM19152v1_genomic.fna ./\n\n$ head GCF_000191525.1_ASM19152v1_genomic.fna &gt;NC_017518.1 Neisseria meningitidis NZ-05/33, complete sequence\nTTCGGCTTAAACCTTATCCATATCCAAACGCATAACCGTAACCCATTCACCGTTATGGAAATGTCGCCCGACAACCGCCC\nAGCCGAATGATTCATAAAATATTTGCACATCAGGCGTATAAAGATACAAGAACTTTATCCCCAGCGAACGCGCTGCGCCT\nATGCAGTGGGCGACCAGCCTCCTGCCAATGCCTTTTCCGCGATATTCAGGTAAAACAAAGACATCACCCAACCAATATTC\nATACTGTGGAAAACTTTCCATATCATGCCGCTTGACCGTAGCCGAACCCAACAGGGTTCCGGAATCATCCACAGCCGCAA\nAAGCCAGCGGCAGTTCGTCATCCTTCAAACACCTGCCGTAATAGGCATGAATCTTATCCACAGAAGACCACGGTTCAAAT\nCCGTGCCACTCCTCAAACAACGCCTGAACCAACCTGCCGATATGCCCGGCTTTCAGCCGTGTAATGAAAACAGTATTGTC\nCACAAAGAGGGAATTCATCGGTCAATTCCCCGACGCTTTCGTTCCCCCTGCGCCGTAAACCGCATTCCAAGCATAGTCCA\nAACGCACTCCGATTTGCCTCAGCTCTTCAGCCTGCCGGGCTTTTTGCGCCATTGCTGCAGGAATTTCCGCTTCCAAACGG\nGCGATGTCTGCCTGAGCCGTCTGCAAACGCCGGCGCGCATCTTCCAAATCCGACTGCATCCCGATGATTTTTCCGTCCAG\n</code></pre>"},{"location":"preparing_data_files/#3-simulating-sequences-with-known-genetics-variants-counts-using-simug","title":"3. Simulating sequences with known genetics variants counts using simuG","text":""},{"location":"preparing_data_files/#i-snp5000","title":"i. SNP=5000","text":"<p><pre><code>$ perl simuG.pl -refseq GCF_000191525.1_ASM19152v1_genomic.fna -snp_count 5000 -prefix Simulation_SNP_5000 -seed 112345678900\n\n$ ls -1sh Simulation_SNP_5000*\n512K Simulation_SNP_5000.refseq2simseq.map.txt\n768K Simulation_SNP_5000.refseq2simseq.SNP.vcf\n2.3M Simulation_SNP_5000.simseq.genome.fa\n\n$ less Simulation_SNP_5000.simseq.genome.fa \n&gt;NC_017518.1\nTTCGGCTTAAACCTTATCCATATCCAAACGCATAACCGTAACCCATTCACCGTTATGGAAATGTCGCCCGACAACCGCCCAGCCGAATGATTCATAAAATATTTGCACATCAGGCGTATAAAGATACAAGAACTTTATCCCCAGCGAACGCGCTGCGCCTATGCAGTGGGCGACCAGCCTCCTGCCAATGCCTTTTCCGCGATATTCAGGTAAAACAAAGACATCAC\n</code></pre> After the simulation the Chromosome number is same. Let's rename it be more clear in the next steps. We can use <code>sed -i</code> for this.  <pre><code>$ sed -i '/&gt;/ s/\\(.*\\)/\\1_SNP_5000/' Simulation_SNP_5000.simseq.genome.fa\n\n$ less Simulation_SNP_5000.simseq.genome.fa\n&gt;NC_017518.1_SNP_5000\nTTCGGCTTAAACCTTATCCATATCCAAACGCATAACCGTAACCCATTCACCGTTATGGAAATGTCGCCCGACAACCGCCCAGCCGAATGATTCATAAAATATTTGCACATCAGGCGTATAAAGATACAAGAACTTTATCCCCAGCGAACGCGCTGCGCCTATGCAGTGGGCGACCAGCCTCCTGCCAATGCCTTTTCCGCGATATTCAGGTAAAACAAAGACATCAC\n</code></pre></p>"},{"location":"preparing_data_files/#ii-indel5000-indel-ratio-11","title":"ii. INDEL=5000 (IN:DEL ratio 1:1)","text":"<p><pre><code>$ perl simuG.pl -refseq GCF_000191525.1_ASM19152v1_genomic.fna -indel_count 5000 -prefix Simulation_INDEL_5000 -seed 212345678900\n$ ls -1tr Simulation_INDEL_5000*\nSimulation_INDEL_5000.refseq2simseq.INDEL.vcf\nSimulation_INDEL_5000.refseq2simseq.map.txt\nSimulation_INDEL_5000.simseq.genome.fa\n\n$ sed -i '/&gt;/ s/\\(.*\\)/\\1_INDEL_5000/' Simulation_INDEL_5000.simseq.genome.fa\n\n$ less Simulation_INDEL_5000.simseq.genome.fa\n&gt;NC_017518.1_INDEL_5000\nTTCGGCTTAAACCTTATCCATATCCAAACGCATAACCGTAACCCATTCACCGTTATGGAAATGTCGCCCGACAACCGCCCAGCCGAATGATTCATAAAATATTTGCACATCAGGCGTATAAAGATACAAGAACTTTATCCCCAGCGAACGCGCTGCGCCTATGCAGTGGGCGACCAGCCTCCTGCCAATGCCTTTTCCGCGATATTCAGGTAAAACAAAGACATCACC\n</code></pre> note: Remeber to use different seeds for each simulation</p>"},{"location":"preparing_data_files/#iii-snp4000-and-indel4000-indel-ratio-14","title":"iii. SNP=4000 and INDEL=4000 (IN:DEL ratio 1:4)","text":"<pre><code>$ perl simuG.pl -refseq GCF_000191525.1_ASM19152v1_genomic.fna -snp_count 4000 -indel_count 4000 -ins_del_ratio 0.25 -prefix Simulation_SNP_4000_INDEL_4000 -seed 312345678900\n$ ls -1tr Simulation_SNP_4000_INDEL_4000*\nSimulation_SNP_4000_INDEL_4000.refseq2simseq.SNP.vcf\nSimulation_SNP_4000_INDEL_4000.refseq2simseq.INDEL.vcf\nSimulation_SNP_4000_INDEL_4000.refseq2simseq.map.txt\nSimulation_SNP_4000_INDEL_4000.simseq.genome.fa\n\n$ sed -i '/&gt;/ s/\\(.*\\)/\\1_SNP_4000_INDEL_4000/' Simulation_SNP_4000_INDEL_4000.simseq.genome.fa\n\n$ less Simulation_SNP_4000_INDEL_4000.simseq.genome.fa\n&gt;NC_017518.1_SNP_4000_INDEL_4000\nTTCGGCTTAAACCTTATCCATATCCAAACGCATAACCGTAACCCATTCACCGTTATGGAAATGTCGCCCGACAACCGCCCAGCCGAATGATTCATAAAATATTTGCACATCAGGCGTATAAAGATACAAGAACTTTATCCCCAGCGAACGCGCTGCGCCTATGCAGTGGGCGACCAGCCTCCTGCCAATGCCTTGTCCGCGATATTCAGGTAAAACAAAGACATCACCCAAC\n</code></pre>"},{"location":"preparing_data_files/#iv-snp4000-indel4000-indel-ratio-14-and-4-inversions","title":"iv. SNP=4000, INDEL=4000 (IN:DEL ratio 1:4) and 4 inversions","text":"<p>To have a more complex sample we'll apply 4 inversions to the above simulated sequence.  <pre><code>$ perl simuG.pl -refseq Simulation_SNP_4000_INDEL_4000.simseq.genome.fa -inversion_count 4 -inversion_min_size 50000 -prefix Simulation_SNP_4000_INDEL_4000_INV_4 -seed 412345678900\n$ ls -1tr Simulation_SNP_4000_INDEL_4000_INV_4*\nSimulation_SNP_4000_INDEL_4000_INV_4.refseq2simseq.inversion.vcf\nSimulation_SNP_4000_INDEL_4000_INV_4.refseq2simseq.map.txt\nSimulation_SNP_4000_INDEL_4000_INV_4.simseq.genome.fa\n\n$ sed -i '/&gt;/ s/\\(.*\\)/\\1_INV_4/' Simulation_SNP_4000_INDEL_4000_INV_4.simseq.genome.fa\n\n$ less Simulation_SNP_4000_INDEL_4000_INV_4.simseq.genome.fa\n&gt;NC_017518.1_SNP_4000_INDEL_4000_INV_4\nTTCGGCTTAAACCTTATCCATATCCAAACGCATAACCGTAACCCATTCACCGTTATGGAAATGTCGCCCGACAACCGCCCAGCCGAATGATTCATAAAATATTTGCACATCAGGCGTATAAAGATACAAGAACTTTATCCCCAGCGAACGCGCTGCGCCTATGCAGTGGGCGACCAGCCTCCTGCCAATGCCTTGTCCGCGATATTCAGGTAAAACAAAGACATCAC\n</code></pre></p>"},{"location":"preparing_data_files/#iv-snp4000-indel4000-indel-ratio-14-and-4-copy-number-variations","title":"iv. SNP=4000, INDEL=4000 (IN:DEL ratio 1:4) and 4 copy number variations","text":"<p>Let's apply 4 copy number variations also and make another simulated sequence.  <pre><code>$ perl simuG.pl -refseq Simulation_SNP_4000_INDEL_4000.simseq.genome.fa -cnv_count 4 -cnv_min_size 20000 -prefix Simulation_SNP_4000_INDEL_4000_CNV_4 -seed 512345678900\n$ ls -1tr Simulation_SNP_4000_INDEL_4000_CNV_4*\nSimulation_SNP_4000_INDEL_4000_CNV_4.refseq2simseq.CNV.vcf\nSimulation_SNP_4000_INDEL_4000_CNV_4.refseq2simseq.map.txt\nSimulation_SNP_4000_INDEL_4000_CNV_4.simseq.genome.fa\n\n$ sed -i '/&gt;/ s/\\(.*\\)/\\1_CNV_4/' Simulation_SNP_4000_INDEL_4000_CNV_4.simseq.genome.fa\n\n$ less Simulation_SNP_4000_INDEL_4000_CNV_4.simseq.genome.fa\n&gt;NC_017518.1_SNP_4000_INDEL_4000_CNV_4\nTTCGGCTTAAACCTTATCCATATCCAAACGCATAACCGTAACCCATTCACCGTTATGGAAATGTCGCCCGACAACCGCCCAGCCGAATGATTCATAAAATATTTGCACATCAGGCGTATAAAGATACAAGAACTTTATCCCCAGCGAACGCGCTGCGCCTATGCAGTGGGCGACCAGCCTCCTGCCAATGCCTTGTCCGCGATATTCAGGTAAAACAAAGACATCAC\n</code></pre></p>"},{"location":"preparing_data_files/#4-concatenate-all-files-and-make-an-index","title":"4. Concatenate all files and make an index","text":"<p>We'll concatenate all these files into one and make an index too <pre><code>$ cat GCF_000191525.1_ASM19152v1_genomic.fna Simulation_SNP_5000.simseq.genome.fa Simulation_INDEL_5000.simseq.genome.fa Simulation_SNP_4000_INDEL_4000.simseq.genome.fa Simulation_SNP_4000_INDEL_4000_INV_4.simseq.genome.fa Simulation_SNP_4000_INDEL_4000_CNV_4.simseq.genome.fa &gt; ASM19152v1_pgsim.fa\n$ module load SAMtools\n$ samtools faidx ASM19152v1_pgsim.fa $ cat ASM19152v1_pgsim.fa.fai NC_017518.1     2248966 64      80      81\nNC_017518.1_SNP_5000    2248966 2277165 2248966 2248967\nNC_017518.1_INDEL_5000  2249048 4526156 2249048 2249049\nNC_017518.1_SNP_4000_INDEL_4000 2242147 6775238 2242147 2242148\nNC_017518.1_SNP_4000_INDEL_4000_INV_4   2242147 9017425 2242147 2242148\nNC_017518.1_SNP_4000_INDEL_4000_CNV_4   2415498 11259612        2415498 2415499\n</code></pre></p>"},{"location":"simulate_and_compare/","title":"Simulate and compare","text":""},{"location":"simulate_and_compare/#a-script-to-simulate-and-compare-variant-calls-generated-using-linear-method-bwa-mem-and-graph-method-vg-giraffe","title":"A script to simulate and compare variant calls generated using linear method (<code>bwa mem</code>) and graph method (<code>vg giraffe</code>)","text":"<p>This script sim_vc_compare.sh peforms the below tasks; (Nesi folder : /nesi/nobackup/nesi02659/pg_workshop/vc_compare_script/) 1. Simulate new sequence with predefined SNPs and INDELs count usnig simuG and create ground truth VCF file (call it as <code>ground_truth.vcf</code>) 2. Simulate reads from the new sequence with with specific coverage depth and read length using <code>wgsim</code> 3. Map the reads with the reference using <code>bwa mem</code> and generate VCF file (call it as <code>simulated.vcf</code>) 4. Compare <code>ground_truth.vcf</code> and <code>simulated.vcf</code> using <code>bcftools isec</code> and generate a report 5. Repeat steps 3 and 4 using <code>vg giraffe</code> 6. Generate a comparision stats report</p> <p>The script accepts following options. </p> <pre><code>$ ./sim_vc_compare.sh --help\nProgram : sim_vc_compare\nVersion : 1.0\nContact : fathima.nuzla.ismail@gmail.com\nUsage   : sim_vc_compare.sh [options]\nOptions :\n-r | --ref STR reference sequence file\n-s | --snp INT Number of SNPs to simulate (Default 0)\n-i | --indel INT Number of INDELs to simulate (Default 0)\n-d | --depth INT Cover depth of the reads (Default 30)\n-l | --length INT of a read (Default 100)\n-o | --output STR Output folder name (Default 'output')\n-h | --help Display this help message\n</code></pre> <p>For an example if we try the below  <pre><code>./sim_vc_compare.sh --ref GCF_000191525.1_ASM19152v1_genomic.fna -snp 5000 --indel 1000\n</code></pre> Script will produce the below report for <code>bwa mem</code>.</p> <pre><code>+------------------------------------------------+\n|  REPORT (BWA MEM)                              |\n+------------------------------------------------+\n|  Ground Truth SNPs                =      5,000 |\n|  Ground Truth INDELs              =      1,000 |\n|  Identified SNPs in Simulation    =      6,646 |\n|  Identified INDELs in Simulation  =      1,666 |\n|  SNPs Private to Simulation       =      1,831 |\n|  INDELs Private to Simulation     =      1,153 |\n|  Exact Matched SNPs               =      4,815 |\n|  Exact Matched INDELs             =        513 |\n|  True Positive (TP)               =      5,328 |\n|  False Positive (FP)              =      2,984 |\n|  True Negative (TN)               =  2,239,982 |\n|  False Negative (FN)              =        672 |\n+------------------------------------------------+\n|  Sensitivity                      =   88.8000% |\n|  Specificity                      =   99.8669% |\n|  F1 Score                         =   74.4550% |\n+------------------------------------------------+\n</code></pre>"},{"location":"simulate_and_compare/#definitions","title":"Definitions","text":"<ol> <li>True Positive (TP) = SNPs+INDELs which are exactly matched in <code>groud_truth.vcf</code> and <code>simulated.vcf</code> (TP=4,815+513=5,328)</li> <li>False Positive (FP) = SNPs+INDELs private to <code>simulated.vcf</code> and not found in <code>groud_truth.vcf</code> (FP=1,831+1,153=2,984)</li> <li>True Negative (TN) = Length of Reference the Sequence - Ground Truth SNPs - Ground Truth INDELs - False Positive. (TN=2,248,966-5,000-1,000-2,984=2,239,982)</li> <li>False Negative (FN) = Ground Truth SNPs+Ground Truth INDELs - True Positive. (FN=5,000+1,000-5,328=672)</li> <li>Sensitivity, Specificity, and F1 Score will be, </li> </ol> <pre><code>\\begin{aligned}\nSensitivity  &amp; = \\frac{TP}{TP+FN} \\\\\n              &amp;  = \\frac{5,328}{5,328+672} \\\\\n              &amp; = 88.8000\\% \\\\ \\\\\nSpecificity &amp; = \\frac{TN}{TN+FP} \\\\\n            &amp;  = \\frac{2,239,982}{2,239,982+2,984} \\\\\n            &amp; = 99.8669\\% \\\\\nF1\\:Score &amp; = \\frac{TP}{TP+\\frac{1}{2}(FP+FN)} \\\\\n            &amp;  = \\frac{5,328}{5,328+0.5\\times(2,984+672)} \\\\ \\\\\n            &amp; = 74.4550\\% \\\\\n\\end{aligned}\n</code></pre> <p>Script will also produce the below report for <code>vg giraffe</code> and the final comparison report.</p> <pre><code>+------------------------------------------------+\n|  REPORT (VG GIRAFFE)                           |\n+------------------------------------------------+\n|  Ground Truth SNPs                =      5,000 |\n|  Ground Truth INDELs              =      1,000 |\n|  Identified SNPs in Simulation    =      6,832 |\n|  Identified INDELs in Simulation  =      1,486 |\n|  SNPs Private to Simulation       =      1,839 |\n|  INDELs Private to Simulation     =        753 |\n|  Exact Matched SNPs               =      4,993 |\n|  Exact Matched INDELs             =        733 |\n|  True Positive (TP)               =      5,726 |\n|  False Positive (FP)              =      2,592 |\n|  True Negative (TN)               =  2,240,374 |\n|  False Negative (FN)              =        274 |\n+------------------------------------------------+\n|  Sensitivity                      =   95.4333% |\n|  Specificity                      =   99.8844% |\n|  F1 Score                         =   79.9832% |\n+------------------------------------------------+\n</code></pre> <pre><code>+-------------------------------------------------------------------------------------------------------------------------+\n|  Method        |     TP       |     TN       |     FP       |     FN       |  Sensitivity |  Specificity |   F1 Score   |\n+-------------------------------------------------------------------------------------------------------------------------+\n|  bwa mem       |       5,328  |   2,239,982  |       2,984  |         672  |    88.8000%  |    99.8669%  |    74.4550%  |\n+-------------------------------------------------------------------------------------------------------------------------+\n|  vg giraffe    |       5,726  |   2,240,374  |       2,592  |         274  |    95.4333%  |    99.8844%  |    79.9832%  |\n+-------------------------------------------------------------------------------------------------------------------------+\n</code></pre>"},{"location":"simulate_and_compare/#references","title":"References","text":"<ol> <li>Alignment of high-throughput sequencing data using BWA. UC Davis Bioinformatics Core 2017 Variant Analysis Workshop. (n.d.). https://ucdavis-bioinformatics-training.github.io/2017-August-Variant-Analysis-Workshop/wednesday/alignment.html </li> <li>Vgteam. (n.d.). Mapping short reads with giraffe. GitHub. https://github.com/vgteam/vg/wiki/Mapping-short-reads-with-Giraffe </li> <li>Paired-End vs. Single-Read Sequencing Technology. (n.d.). https://www.illumina.com/science/technology/next-generation-sequencing/plan-experiments/paired-end-vs-single-read.html</li> <li>Buffalo, V. (2015). Bioinformatics Data Skills: Reproducible and Robust Research with Open Source Tools. \u201cO\u2019Reilly Media, Inc.\u201d</li> <li>Dudley, J. T., &amp; Karczewski, K. J. (2013). Exploring Personal Genomics. OUP Oxford.</li> <li>Samtools - Documentation. (n.d.). https://www.htslib.org/doc/</li> <li>Bash Reference Manual. (n.d.). https://www.gnu.org/software/bash/manual/bash.html</li> <li>Yjx. (n.d.). GitHub - yjx1217/simuG: simuG: a general-purpose genome simulator. GitHub. https://github.com/yjx1217/simuG</li> <li>The Sequencing Center. (2022, September 26). What is de novo assembly? - The Sequencing Center. https://thesequencingcenter.com/knowledge-base/de-novo-assembly/</li> <li>Lh. (n.d.). GitHub - lh3/wgsim: Reads simulator. GitHub. https://github.com/lh3/wgsim</li> <li>Wikipedia contributors. (2023). Sensitivity and specificity. Wikipedia. https://en.wikipedia.org/wiki/Sensitivity_and_specificity</li> </ol>"},{"location":"vc_position_based_comparison/","title":"How to compare 2 VCF files based on the exact variant position?","text":"<p>When simulating the new sequences in the previous procedure Preparing required data files with simuG tool related VCF files were also generated (e.g. Simulation_SNP_5000.refseq2simseq.SNP.vcf). We can compare that VCF file with linear based VCF file and the graph based files to find variant differences considering the exact bp positions. <code>bcftools isec</code> command can be used for this. </p> <p>If the ground truch simulated VCF is <code>Simulation_SNP_5000.refseq2simseq.SNP.vcf</code> (generated by https://github.com/nuzla/Pangenome-Graphs-Workshop/blob/main/preparing_data_files.md) and the linear method based vcf file (generated by https://github.com/nuzla/Pangenome-Graphs-Workshop/blob/main/linear_reference_vc.md) is <code>Simulation_SNP_5000.bwa.30x.100R.vcf</code>; first we need to <code>bgzip</code> the files and make indexes. </p>"},{"location":"vc_position_based_comparison/#ground-truth-vs-linear-based-variant-comparision","title":"Ground Truth vs Linear based variant comparision","text":"<pre><code>bgzip Simulation_SNP_5000.refseq2simseq.SNP.vcf\nbgzip Simulation_SNP_5000.bwa.30x.100R.vcf\nbcftools index Simulation_SNP_5000.bwa.30x.100R.vcf.gz\nbcftools index Simulation_SNP_5000.refseq2simseq.SNP.vcf.gz\n</code></pre> <p>Then use the below commands to compare. Here the option <code>-c none</code> will do the exact matching <code>-p</code> for specifying the output folder. </p> <pre><code>$ bcftools isec -c none -p output_SNP_5000_bwa.30x.100R Simulation_SNP_5000.refseq2simseq.SNP.vcf.gz Simulation_SNP_5000.bwa.30x.100R.vcf.gz\nls -1sh output_SNP_5000_bwa.30x.100R\ntotal 2.3M\n256K 0000.vcf\n512K 0001.vcf\n768K 0002.vcf\n768K 0003.vcf\n 512 README.txt\n</code></pre> <p>The README.txt file has the details about what each vcf file has. </p> <pre><code>$ cat output_SNP_5000_bwa.30x.100R/README.txt \nThis file was produced by vcfisec.\nThe command line was:   bcftools isec  -c none -p output_SNP_5000_bwa.30x.100R Simulation_SNP_5000.refseq2simseq.SNP.vcf.gz Simulation_SNP_5000.bwa.30x.100R.vcf.gz\n\nUsing the following file names:\noutput_SNP_5000_bwa.30x.100R/0000.vcf   for records private to  Simulation_SNP_5000.refseq2simseq.SNP.vcf.gz\noutput_SNP_5000_bwa.30x.100R/0001.vcf   for records private to  Simulation_SNP_5000.bwa.30x.100R.vcf.gz\noutput_SNP_5000_bwa.30x.100R/0002.vcf   for records from Simulation_SNP_5000.refseq2simseq.SNP.vcf.gz shared by both    Simulation_SNP_5000.refseq2simseq.SNP.vcf.gz Simulation_SNP_5000.bwa.30x.100R.vcf.gz\noutput_SNP_5000_bwa.30x.100R/0003.vcf   for records from Simulation_SNP_5000.bwa.30x.100R.vcf.gz shared by both Simulation_SNP_5000.refseq2simseq.SNP.vcf.gz Simulation_SNP_5000.bwa.30x.100R.vcf.gz\n</code></pre> <p>As per this explnation, 0002.vcf file should have the True Positive (TP) stats. </p> <pre><code>$ bcftools stats output_SNP_5000_bwa.30x.100R/0002.vcf | head -40\n# This file was produced by bcftools stats (1.9+htslib-1.9) and can be plotted using plot-vcfstats.\n# The command line was: bcftools stats  output_SNP_5000_bwa.30x.100R/0002.vcf\n#\n# Definition of sets:\n# ID    [2]id   [3]tab-separated file names\nID      0       output_SNP_5000_bwa.30x.100R/0002.vcf\n# SN, Summary numbers:\n#   number of records   .. number of data rows in the VCF\n#   number of no-ALTs   .. reference-only sites, ALT is either \".\" or identical to REF\n#   number of SNPs      .. number of rows with a SNP\n#   number of MNPs      .. number of rows with a MNP, such as CC&gt;TT\n#   number of indels    .. number of rows with an indel\n#   number of others    .. number of rows with other type, for example a symbolic allele or\n#                          a complex substitution, such as ACT&gt;TCGA\n#   number of multiallelic sites     .. number of rows with multiple alternate alleles\n#   number of multiallelic SNP sites .. number of rows with multiple alternate alleles, all SNPs\n# \n#   Note that rows containing multiple types will be counted multiple times, in each\n#   counter. For example, a row with a SNP and an indel increments both the SNP and\n#   the indel counter.\n# \n# SN    [2]id   [3]key  [4]value\nSN      0       number of samples:      0\nSN      0       number of records:      4667\nSN      0       number of no-ALTs:      0\nSN      0       number of SNPs: 4667\nSN      0       number of MNPs: 0\nSN      0       number of indels:       0\nSN      0       number of others:       0\nSN      0       number of multiallelic sites:   0\nSN      0       number of multiallelic SNP sites:       0\n# TSTV, transitions/transversions:\n# TSTV  [2]id   [3]ts   [4]tv   [5]ts/tv        [6]ts (1st ALT) [7]tv (1st ALT) [8]ts/tv (1st ALT)\nTSTV    0       1550    3117    0.50    1550    3117    0.50\n# SiS, Singleton stats:\n# SiS   [2]id   [3]allele count [4]number of SNPs       [5]number of transitions        [6]number of transversions      [7]number of indels     [8]repeat-consistent    [9]repeat-inconsistent        [10]not applicable\nSiS     0       1       4667    1550    3117    0       0       0       0\n# AF, Stats by non-reference allele frequency:\n# AF    [2]id   [3]allele frequency     [4]number of SNPs       [5]number of transitions        [6]number of transversions      [7]number of indels     [8]repeat-consistent [9]repeat-inconsistent   [10]not applicable\nAF      0       0.000000        4667    1550    3117    0       0       0       0\n</code></pre> <p>When simulating multiple types of variants using simuG tool it creates multiple VCF files as well. We need to merge them and create one VCF file before comapring. For an example for the simulated sample NC_017518.1_SNP_4000_INDEL_4000, </p> <pre><code>$ ls -1hs Simulation_SNP_4000_INDEL_4000.*\n768K Simulation_SNP_4000_INDEL_4000.refseq2simseq.INDEL.vcf\n768K Simulation_SNP_4000_INDEL_4000.refseq2simseq.map.txt\n768K Simulation_SNP_4000_INDEL_4000.refseq2simseq.SNP.vcf\n2.3M Simulation_SNP_4000_INDEL_4000.simseq.genome.fa\n</code></pre> <p>zip the files and making indexes. </p> <pre><code>$ bgzip Simulation_SNP_4000_INDEL_4000.refseq2simseq.INDEL.vcf\n$ bgzip Simulation_SNP_4000_INDEL_4000.refseq2simseq.SNP.vcf\n$ bcftools index Simulation_SNP_4000_INDEL_4000.refseq2simseq.SNP.vcf.gz\n$ bcftools index Simulation_SNP_4000_INDEL_4000.refseq2simseq.INDEL.vcf.gz\n</code></pre> <p>Merge 2 vcf files usnimng <code>bcftools</code></p> <pre><code>bcftools merge Simulation_SNP_4000_INDEL_4000.refseq2simseq.SNP.vcf.gz Simulation_SNP_4000_INDEL_4000.refseq2simseq.INDEL.vcf.gz -O z -o Simulation_SNP_4000_INDEL_4000.vcf.gz\n</code></pre> <p>Stats of the merged vcf file should show 4000 SNPs and 4000 INDELs.</p> <pre><code>$ bcftools stats Simulation_SNP_4000_INDEL_4000.vcf.gz | less\n# This file was produced by bcftools stats (1.9+htslib-1.9) and can be plotted using plot-vcfstats.\n# The command line was: bcftools stats  Simulation_SNP_4000_INDEL_4000.vcf.gz\n#\n# Definition of sets:\n# ID    [2]id   [3]tab-separated file names\nID      0       Simulation_SNP_4000_INDEL_4000.vcf.gz\n# SN, Summary numbers:\n#   number of records   .. number of data rows in the VCF\n#   number of no-ALTs   .. reference-only sites, ALT is either \".\" or identical to REF\n#   number of SNPs      .. number of rows with a SNP\n#   number of MNPs      .. number of rows with a MNP, such as CC&gt;TT\n#   number of indels    .. number of rows with an indel\n#   number of others    .. number of rows with other type, for example a symbolic allele or\n#                          a complex substitution, such as ACT&gt;TCGA\n#   number of multiallelic sites     .. number of rows with multiple alternate alleles\n#   number of multiallelic SNP sites .. number of rows with multiple alternate alleles, all SNPs\n# \n#   Note that rows containing multiple types will be counted multiple times, in each\n#   counter. For example, a row with a SNP and an indel increments both the SNP and\n#   the indel counter.\n# \n# SN    [2]id   [3]key  [4]value\nSN      0       number of samples:      0\nSN      0       number of records:      8000\nSN      0       number of no-ALTs:      0\nSN      0       number of SNPs: 4000\nSN      0       number of MNPs: 0\nSN      0       number of indels:       4000\nSN      0       number of others:       0\nSN      0       number of multiallelic sites:   0\nSN      0       number of multiallelic SNP sites:       0\n# TSTV, transitions/transversions:\n# TSTV  [2]id   [3]ts   [4]tv   [5]ts/tv        [6]ts (1st ALT) [7]tv (1st ALT) [8]ts/tv (1st ALT)\nTSTV    0       1372    2628    0.52    1372    2628    0.52\n# SiS, Singleton stats:\n# SiS   [2]id   [3]allele count [4]number of SNPs       [5]number of transitions        [6]number of transversions      [7]number of indels     [8]repeat-consistent    [9]repeat-inconsistent  [10]not applicable\nSiS     0       1       4000    1372    2628    4000    0       0       4000\n</code></pre> <p>Now  we can apply the same procedure for comparision using <code>bcftools isec</code>.</p>"}]}